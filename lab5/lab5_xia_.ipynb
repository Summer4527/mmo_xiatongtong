{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab5 xia.",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9C3yHZSqnERf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №5\n",
        "## \"**Предобработка и классификация текстовых данных**\"\n",
        "\n",
        "Выполнила: Ся Тунтун   \n",
        "Группа: ИУ5-23М  \n",
        "\n",
        "  \n",
        "  \n",
        "**Цель лабораторной работы:** изучение методов предобработки и классификации тестовых данных.  \n",
        "\n",
        "  \n",
        "**Задание:**  \n",
        "\n",
        "1.   Для произвольного предложения или текста решите следующие задачи:\n",
        "\n",
        "*   Токенизация.\n",
        "*   Частеречная разметка.\n",
        "*   Лемматизация.\n",
        "*   Выделение (распознавание) именованных сущностей.\n",
        "*   Разбор предложения.\n",
        "\n",
        "2.   Для произвольного набора данных, предназначенного для классификации текстов, решите задачу классификации текста двумя способами:\n",
        "\n",
        "*   Способ 1. На основе CountVectorizer или TfidfVectorizer.\n",
        "*   Способ 2. На основе моделей word2vec или Glove или fastText.\n",
        "*   Сравните качество полученных моделей.\n",
        "\n",
        "Для поиска наборов данных в поисковой системе можно использовать ключевые слова \"datasets for text classification\"."
      ],
      "metadata": {
        "id": "bNYEYE3140Ga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzh6KcoV3wVA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk import tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m01J02y1NYfx",
        "outputId": "127afb75-bf04-4a1f-abab-47b1cfe0fab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: natasha in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.15.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.21.6)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKkgufKvQK-1",
        "outputId": "94aaa054-f6d1-4fa8-82ee-bd229b788339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.7/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим датасет с классификацией записей в сети Твиттер и предполагемой тональностью их содержимого:"
      ],
      "metadata": {
        "id": "I0mV-C-z5t6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Подключение к gogle диску\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YBhjfF4D-WuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Вывод содержимого папки на диске\n",
        "# import os\n",
        "# data_root = '/content/drive/MyDrive/MMO'\n",
        "# print(os.listdir(data_root))"
      ],
      "metadata": {
        "id": "LiLi-Bzo-XjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Распаковка архива с датасетом\n",
        "# !unzip /content/drive/MyDrive/MMO/train.zip\n",
        "# # Unpack files from zip-file\n",
        "# # import zipfile\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/MMO/ml-latest-small.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall(BASE_DIR)"
      ],
      "metadata": {
        "id": "9gpTYvv--3j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_class = pd.read_csv('/content/train.csv', sep=\",\")\n",
        "# df_class.head()"
      ],
      "metadata": {
        "id": "GU4q6j1y5wJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Дмитрий Иванович Менделеев родился 27 января (8 февраля) 1834 года в Тобольске в семье Ивана Павловича Менделеева, в то время занимавшего должность директора Тобольской гимназии и училищ Тобольского округа, и Марии Дмитриевны Менделеевой (Корнильевой).Эти змееволосые дамочки уже начали раздражать Перси.\n",
        "Они должны были умереть еще три дня назад, когда он сбросил на них ящик с шарами для боулинга в «Баргин-Марте» в Напе. Они должны были отдать концы два дня назад, после того как он переехал их полицейским автомобилем в Мартинесе. И уж точно они должны были сдохнуть, когда он отрезал им головы сегодня утром в Тилден-парке.\n",
        "Перси убивал их и своими глазами видел, как они обращаются в прах, но эти гнусные тетки неизменно возвращались к жизни. Он, похоже, даже не мог надолго от них оторваться.\n",
        "Он взобрался на вершину холма и перевел дух. Сколько времени прошло с тех пор, как он прикончил их в последний раз? Часа два, наверное. Кажется, они теперь не умирают больше чем на два часа…\n",
        "В последние дни Перси почти не спал. Ел он то, что удавалось стянуть по дороге, – жевательную конфету из торгового автомата, черствый бублик или лепешку буррито, хотя прежде он еще так низко не опускался. Одежда его порвалась, местами обгорела и вся была заляпана слюной монстров.\n",
        "Перси до сих пор был жив только потому, что две змееволосые дамочки (они называли себя горгонами) тоже, похоже, оказались не в состоянии его убить. Их когти не оставляли следа на его коже. Если они пытались его укусить – зубы у них ломались. Но Перси уже был на пределе. Скоро он свалится от истощения, а тогда… хоть его и трудно убить, горгоны найдут способ. Он в этом не сомневался.'''\n",
        "\n",
        "text2 = 'МГТУ им. Н. Э. Ба́умана  — российский национальный исследовательский университет, Предыдущее название университета «Моско́вское вы́сшее техни́ческое учи́лище им. Н. Э. Ба́умана» было присвоено ему в честь революционера Николая Эрнестовича Баумана, '\n",
        "\n",
        "test_text = 'Праздник весны является самым любимым праздником китайцев .Накануне его китайцы ,которые　рабатают или занимаются в других местах, несмотря на далёкий путь, всегда спешат к родным очагам, чтобы провести этот праздник дома, со своими близкими.'"
      ],
      "metadata": {
        "id": "RZwrYgGXNskJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # выделим тестовое сообщение, с которым затем будем выполнять задачи предобработки текста\n",
        "# test_val = 100\n",
        "# texts = df_class['content']\n",
        "# test_text = texts.iloc[test_val]\n",
        "# test_text"
      ],
      "metadata": {
        "id": "OIqy1QZe5xvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Предобработка текста"
      ],
      "metadata": {
        "id": "TkogmKz-51BB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Токенизация"
      ],
      "metadata": {
        "id": "yeMZx50756Hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLTK**  \n",
        "Содержит большое количество токенизаторов. На практике они не всегда стабильно работают для русского языка."
      ],
      "metadata": {
        "id": "i_Bz3tDoptey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "7MxeqYzP59CZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63ba8d7-7d3a-4728-e880-9cf2fbfa118a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import tokenize\n",
        "dir(tokenize)[:18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_UQdnpSo8fi",
        "outputId": "26faa678-c74b-48f6-93eb-2f18012e01b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BlanklineTokenizer',\n",
              " 'LineTokenizer',\n",
              " 'MWETokenizer',\n",
              " 'PunktSentenceTokenizer',\n",
              " 'RegexpTokenizer',\n",
              " 'ReppTokenizer',\n",
              " 'SExprTokenizer',\n",
              " 'SpaceTokenizer',\n",
              " 'StanfordSegmenter',\n",
              " 'TabTokenizer',\n",
              " 'TextTilingTokenizer',\n",
              " 'ToktokTokenizer',\n",
              " 'TreebankWordTokenizer',\n",
              " 'TweetTokenizer',\n",
              " 'WhitespaceTokenizer',\n",
              " 'WordPunctTokenizer',\n",
              " '__builtins__',\n",
              " '__cached__']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация по предложениям:"
      ],
      "metadata": {
        "id": "5RZ-21M35_dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_tk_sents = nltk.tokenize.sent_tokenize(test_text)\n",
        "print(len(nltk_tk_sents))\n",
        "nltk_tk_sents"
      ],
      "metadata": {
        "id": "K9yKP2015-ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f2db6d-b3ab-41ba-8c4f-55402881fa17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Праздник весны является самым любимым праздником китайцев .Накануне его китайцы ,которые\\u3000рабатают или занимаются в других местах, несмотря на далёкий путь, всегда спешат к родным очагам, чтобы провести этот праздник дома, со своими близкими.']"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация по словам:"
      ],
      "metadata": {
        "id": "OqFfWpCf6FaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk_tk_1 = nltk.WordPunctTokenizer()\n",
        "nltk_tk_1.tokenize(test_text)"
      ],
      "metadata": {
        "id": "jUl15WUK6HQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ead3d2c-0634-4edb-9fab-933de3e5d59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Праздник',\n",
              " 'весны',\n",
              " 'является',\n",
              " 'самым',\n",
              " 'любимым',\n",
              " 'праздником',\n",
              " 'китайцев',\n",
              " '.',\n",
              " 'Накануне',\n",
              " 'его',\n",
              " 'китайцы',\n",
              " ',',\n",
              " 'которые',\n",
              " 'рабатают',\n",
              " 'или',\n",
              " 'занимаются',\n",
              " 'в',\n",
              " 'других',\n",
              " 'местах',\n",
              " ',',\n",
              " 'несмотря',\n",
              " 'на',\n",
              " 'далёкий',\n",
              " 'путь',\n",
              " ',',\n",
              " 'всегда',\n",
              " 'спешат',\n",
              " 'к',\n",
              " 'родным',\n",
              " 'очагам',\n",
              " ',',\n",
              " 'чтобы',\n",
              " 'провести',\n",
              " 'этот',\n",
              " 'праздник',\n",
              " 'дома',\n",
              " ',',\n",
              " 'со',\n",
              " 'своими',\n",
              " 'близкими',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**  \n",
        "Для токенизации используется библиотека https://github.com/natasha/razdel"
      ],
      "metadata": {
        "id": "xbJGrVnSpylg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize, sentenize"
      ],
      "metadata": {
        "id": "NSUgaUp-QQP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_tok_text = list(tokenize(text))\n",
        "n_tok_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DshIy77eQcA4",
        "outputId": "0eec7efd-aa2c-484b-92bd-e5e2060ac03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 7, 'Дмитрий'),\n",
              " Substring(8, 16, 'Иванович'),\n",
              " Substring(17, 26, 'Менделеев'),\n",
              " Substring(27, 34, 'родился'),\n",
              " Substring(35, 37, '27'),\n",
              " Substring(38, 44, 'января'),\n",
              " Substring(45, 46, '('),\n",
              " Substring(46, 47, '8'),\n",
              " Substring(48, 55, 'февраля'),\n",
              " Substring(55, 56, ')'),\n",
              " Substring(57, 61, '1834'),\n",
              " Substring(62, 66, 'года'),\n",
              " Substring(67, 68, 'в'),\n",
              " Substring(69, 78, 'Тобольске'),\n",
              " Substring(79, 80, 'в'),\n",
              " Substring(81, 86, 'семье'),\n",
              " Substring(87, 92, 'Ивана'),\n",
              " Substring(93, 102, 'Павловича'),\n",
              " Substring(103, 113, 'Менделеева'),\n",
              " Substring(113, 114, ','),\n",
              " Substring(115, 116, 'в'),\n",
              " Substring(117, 119, 'то'),\n",
              " Substring(120, 125, 'время'),\n",
              " Substring(126, 137, 'занимавшего'),\n",
              " Substring(138, 147, 'должность'),\n",
              " Substring(148, 157, 'директора'),\n",
              " Substring(158, 168, 'Тобольской'),\n",
              " Substring(169, 177, 'гимназии'),\n",
              " Substring(178, 179, 'и'),\n",
              " Substring(180, 186, 'училищ'),\n",
              " Substring(187, 198, 'Тобольского'),\n",
              " Substring(199, 205, 'округа'),\n",
              " Substring(205, 206, ','),\n",
              " Substring(207, 208, 'и'),\n",
              " Substring(209, 214, 'Марии'),\n",
              " Substring(215, 225, 'Дмитриевны'),\n",
              " Substring(226, 237, 'Менделеевой'),\n",
              " Substring(238, 239, '('),\n",
              " Substring(239, 250, 'Корнильевой'),\n",
              " Substring(250, 251, ')'),\n",
              " Substring(251, 252, '.'),\n",
              " Substring(252, 255, 'Эти'),\n",
              " Substring(256, 267, 'змееволосые'),\n",
              " Substring(268, 275, 'дамочки'),\n",
              " Substring(276, 279, 'уже'),\n",
              " Substring(280, 286, 'начали'),\n",
              " Substring(287, 297, 'раздражать'),\n",
              " Substring(298, 303, 'Перси'),\n",
              " Substring(303, 304, '.'),\n",
              " Substring(305, 308, 'Они'),\n",
              " Substring(309, 315, 'должны'),\n",
              " Substring(316, 320, 'были'),\n",
              " Substring(321, 328, 'умереть'),\n",
              " Substring(329, 332, 'еще'),\n",
              " Substring(333, 336, 'три'),\n",
              " Substring(337, 340, 'дня'),\n",
              " Substring(341, 346, 'назад'),\n",
              " Substring(346, 347, ','),\n",
              " Substring(348, 353, 'когда'),\n",
              " Substring(354, 356, 'он'),\n",
              " Substring(357, 364, 'сбросил'),\n",
              " Substring(365, 367, 'на'),\n",
              " Substring(368, 371, 'них'),\n",
              " Substring(372, 376, 'ящик'),\n",
              " Substring(377, 378, 'с'),\n",
              " Substring(379, 385, 'шарами'),\n",
              " Substring(386, 389, 'для'),\n",
              " Substring(390, 398, 'боулинга'),\n",
              " Substring(399, 400, 'в'),\n",
              " Substring(401, 402, '«'),\n",
              " Substring(402, 414, 'Баргин-Марте'),\n",
              " Substring(414, 415, '»'),\n",
              " Substring(416, 417, 'в'),\n",
              " Substring(418, 422, 'Напе'),\n",
              " Substring(422, 423, '.'),\n",
              " Substring(424, 427, 'Они'),\n",
              " Substring(428, 434, 'должны'),\n",
              " Substring(435, 439, 'были'),\n",
              " Substring(440, 446, 'отдать'),\n",
              " Substring(447, 452, 'концы'),\n",
              " Substring(453, 456, 'два'),\n",
              " Substring(457, 460, 'дня'),\n",
              " Substring(461, 466, 'назад'),\n",
              " Substring(466, 467, ','),\n",
              " Substring(468, 473, 'после'),\n",
              " Substring(474, 478, 'того'),\n",
              " Substring(479, 482, 'как'),\n",
              " Substring(483, 485, 'он'),\n",
              " Substring(486, 494, 'переехал'),\n",
              " Substring(495, 497, 'их'),\n",
              " Substring(498, 509, 'полицейским'),\n",
              " Substring(510, 521, 'автомобилем'),\n",
              " Substring(522, 523, 'в'),\n",
              " Substring(524, 533, 'Мартинесе'),\n",
              " Substring(533, 534, '.'),\n",
              " Substring(535, 536, 'И'),\n",
              " Substring(537, 539, 'уж'),\n",
              " Substring(540, 545, 'точно'),\n",
              " Substring(546, 549, 'они'),\n",
              " Substring(550, 556, 'должны'),\n",
              " Substring(557, 561, 'были'),\n",
              " Substring(562, 570, 'сдохнуть'),\n",
              " Substring(570, 571, ','),\n",
              " Substring(572, 577, 'когда'),\n",
              " Substring(578, 580, 'он'),\n",
              " Substring(581, 588, 'отрезал'),\n",
              " Substring(589, 591, 'им'),\n",
              " Substring(592, 598, 'головы'),\n",
              " Substring(599, 606, 'сегодня'),\n",
              " Substring(607, 612, 'утром'),\n",
              " Substring(613, 614, 'в'),\n",
              " Substring(615, 627, 'Тилден-парке'),\n",
              " Substring(627, 628, '.'),\n",
              " Substring(629, 634, 'Перси'),\n",
              " Substring(635, 641, 'убивал'),\n",
              " Substring(642, 644, 'их'),\n",
              " Substring(645, 646, 'и'),\n",
              " Substring(647, 653, 'своими'),\n",
              " Substring(654, 661, 'глазами'),\n",
              " Substring(662, 667, 'видел'),\n",
              " Substring(667, 668, ','),\n",
              " Substring(669, 672, 'как'),\n",
              " Substring(673, 676, 'они'),\n",
              " Substring(677, 687, 'обращаются'),\n",
              " Substring(688, 689, 'в'),\n",
              " Substring(690, 694, 'прах'),\n",
              " Substring(694, 695, ','),\n",
              " Substring(696, 698, 'но'),\n",
              " Substring(699, 702, 'эти'),\n",
              " Substring(703, 710, 'гнусные'),\n",
              " Substring(711, 716, 'тетки'),\n",
              " Substring(717, 726, 'неизменно'),\n",
              " Substring(727, 739, 'возвращались'),\n",
              " Substring(740, 741, 'к'),\n",
              " Substring(742, 747, 'жизни'),\n",
              " Substring(747, 748, '.'),\n",
              " Substring(749, 751, 'Он'),\n",
              " Substring(751, 752, ','),\n",
              " Substring(753, 759, 'похоже'),\n",
              " Substring(759, 760, ','),\n",
              " Substring(761, 765, 'даже'),\n",
              " Substring(766, 768, 'не'),\n",
              " Substring(769, 772, 'мог'),\n",
              " Substring(773, 780, 'надолго'),\n",
              " Substring(781, 783, 'от'),\n",
              " Substring(784, 787, 'них'),\n",
              " Substring(788, 798, 'оторваться'),\n",
              " Substring(798, 799, '.'),\n",
              " Substring(800, 802, 'Он'),\n",
              " Substring(803, 812, 'взобрался'),\n",
              " Substring(813, 815, 'на'),\n",
              " Substring(816, 823, 'вершину'),\n",
              " Substring(824, 829, 'холма'),\n",
              " Substring(830, 831, 'и'),\n",
              " Substring(832, 839, 'перевел'),\n",
              " Substring(840, 843, 'дух'),\n",
              " Substring(843, 844, '.'),\n",
              " Substring(845, 852, 'Сколько'),\n",
              " Substring(853, 860, 'времени'),\n",
              " Substring(861, 867, 'прошло'),\n",
              " Substring(868, 869, 'с'),\n",
              " Substring(870, 873, 'тех'),\n",
              " Substring(874, 877, 'пор'),\n",
              " Substring(877, 878, ','),\n",
              " Substring(879, 882, 'как'),\n",
              " Substring(883, 885, 'он'),\n",
              " Substring(886, 895, 'прикончил'),\n",
              " Substring(896, 898, 'их'),\n",
              " Substring(899, 900, 'в'),\n",
              " Substring(901, 910, 'последний'),\n",
              " Substring(911, 914, 'раз'),\n",
              " Substring(914, 915, '?'),\n",
              " Substring(916, 920, 'Часа'),\n",
              " Substring(921, 924, 'два'),\n",
              " Substring(924, 925, ','),\n",
              " Substring(926, 934, 'наверное'),\n",
              " Substring(934, 935, '.'),\n",
              " Substring(936, 943, 'Кажется'),\n",
              " Substring(943, 944, ','),\n",
              " Substring(945, 948, 'они'),\n",
              " Substring(949, 955, 'теперь'),\n",
              " Substring(956, 958, 'не'),\n",
              " Substring(959, 966, 'умирают'),\n",
              " Substring(967, 973, 'больше'),\n",
              " Substring(974, 977, 'чем'),\n",
              " Substring(978, 980, 'на'),\n",
              " Substring(981, 984, 'два'),\n",
              " Substring(985, 989, 'часа'),\n",
              " Substring(989, 990, '…'),\n",
              " Substring(991, 992, 'В'),\n",
              " Substring(993, 1002, 'последние'),\n",
              " Substring(1003, 1006, 'дни'),\n",
              " Substring(1007, 1012, 'Перси'),\n",
              " Substring(1013, 1018, 'почти'),\n",
              " Substring(1019, 1021, 'не'),\n",
              " Substring(1022, 1026, 'спал'),\n",
              " Substring(1026, 1027, '.'),\n",
              " Substring(1028, 1030, 'Ел'),\n",
              " Substring(1031, 1033, 'он'),\n",
              " Substring(1034, 1036, 'то'),\n",
              " Substring(1036, 1037, ','),\n",
              " Substring(1038, 1041, 'что'),\n",
              " Substring(1042, 1051, 'удавалось'),\n",
              " Substring(1052, 1059, 'стянуть'),\n",
              " Substring(1060, 1062, 'по'),\n",
              " Substring(1063, 1069, 'дороге'),\n",
              " Substring(1069, 1070, ','),\n",
              " Substring(1071, 1072, '–'),\n",
              " Substring(1073, 1084, 'жевательную'),\n",
              " Substring(1085, 1092, 'конфету'),\n",
              " Substring(1093, 1095, 'из'),\n",
              " Substring(1096, 1105, 'торгового'),\n",
              " Substring(1106, 1114, 'автомата'),\n",
              " Substring(1114, 1115, ','),\n",
              " Substring(1116, 1124, 'черствый'),\n",
              " Substring(1125, 1131, 'бублик'),\n",
              " Substring(1132, 1135, 'или'),\n",
              " Substring(1136, 1143, 'лепешку'),\n",
              " Substring(1144, 1151, 'буррито'),\n",
              " Substring(1151, 1152, ','),\n",
              " Substring(1153, 1157, 'хотя'),\n",
              " Substring(1158, 1164, 'прежде'),\n",
              " Substring(1165, 1167, 'он'),\n",
              " Substring(1168, 1171, 'еще'),\n",
              " Substring(1172, 1175, 'так'),\n",
              " Substring(1176, 1181, 'низко'),\n",
              " Substring(1182, 1184, 'не'),\n",
              " Substring(1185, 1194, 'опускался'),\n",
              " Substring(1194, 1195, '.'),\n",
              " Substring(1196, 1202, 'Одежда'),\n",
              " Substring(1203, 1206, 'его'),\n",
              " Substring(1207, 1216, 'порвалась'),\n",
              " Substring(1216, 1217, ','),\n",
              " Substring(1218, 1225, 'местами'),\n",
              " Substring(1226, 1234, 'обгорела'),\n",
              " Substring(1235, 1236, 'и'),\n",
              " Substring(1237, 1240, 'вся'),\n",
              " Substring(1241, 1245, 'была'),\n",
              " Substring(1246, 1254, 'заляпана'),\n",
              " Substring(1255, 1261, 'слюной'),\n",
              " Substring(1262, 1270, 'монстров'),\n",
              " Substring(1270, 1271, '.'),\n",
              " Substring(1272, 1277, 'Перси'),\n",
              " Substring(1278, 1280, 'до'),\n",
              " Substring(1281, 1284, 'сих'),\n",
              " Substring(1285, 1288, 'пор'),\n",
              " Substring(1289, 1292, 'был'),\n",
              " Substring(1293, 1296, 'жив'),\n",
              " Substring(1297, 1303, 'только'),\n",
              " Substring(1304, 1310, 'потому'),\n",
              " Substring(1310, 1311, ','),\n",
              " Substring(1312, 1315, 'что'),\n",
              " Substring(1316, 1319, 'две'),\n",
              " Substring(1320, 1331, 'змееволосые'),\n",
              " Substring(1332, 1339, 'дамочки'),\n",
              " Substring(1340, 1341, '('),\n",
              " Substring(1341, 1344, 'они'),\n",
              " Substring(1345, 1353, 'называли'),\n",
              " Substring(1354, 1358, 'себя'),\n",
              " Substring(1359, 1368, 'горгонами'),\n",
              " Substring(1368, 1369, ')'),\n",
              " Substring(1370, 1374, 'тоже'),\n",
              " Substring(1374, 1375, ','),\n",
              " Substring(1376, 1382, 'похоже'),\n",
              " Substring(1382, 1383, ','),\n",
              " Substring(1384, 1393, 'оказались'),\n",
              " Substring(1394, 1396, 'не'),\n",
              " Substring(1397, 1398, 'в'),\n",
              " Substring(1399, 1408, 'состоянии'),\n",
              " Substring(1409, 1412, 'его'),\n",
              " Substring(1413, 1418, 'убить'),\n",
              " Substring(1418, 1419, '.'),\n",
              " Substring(1420, 1422, 'Их'),\n",
              " Substring(1423, 1428, 'когти'),\n",
              " Substring(1429, 1431, 'не'),\n",
              " Substring(1432, 1441, 'оставляли'),\n",
              " Substring(1442, 1447, 'следа'),\n",
              " Substring(1448, 1450, 'на'),\n",
              " Substring(1451, 1454, 'его'),\n",
              " Substring(1455, 1459, 'коже'),\n",
              " Substring(1459, 1460, '.'),\n",
              " Substring(1461, 1465, 'Если'),\n",
              " Substring(1466, 1469, 'они'),\n",
              " Substring(1470, 1478, 'пытались'),\n",
              " Substring(1479, 1482, 'его'),\n",
              " Substring(1483, 1490, 'укусить'),\n",
              " Substring(1491, 1492, '–'),\n",
              " Substring(1493, 1497, 'зубы'),\n",
              " Substring(1498, 1499, 'у'),\n",
              " Substring(1500, 1503, 'них'),\n",
              " Substring(1504, 1512, 'ломались'),\n",
              " Substring(1512, 1513, '.'),\n",
              " Substring(1514, 1516, 'Но'),\n",
              " Substring(1517, 1522, 'Перси'),\n",
              " Substring(1523, 1526, 'уже'),\n",
              " Substring(1527, 1530, 'был'),\n",
              " Substring(1531, 1533, 'на'),\n",
              " Substring(1534, 1541, 'пределе'),\n",
              " Substring(1541, 1542, '.'),\n",
              " Substring(1543, 1548, 'Скоро'),\n",
              " Substring(1549, 1551, 'он'),\n",
              " Substring(1552, 1560, 'свалится'),\n",
              " Substring(1561, 1563, 'от'),\n",
              " Substring(1564, 1573, 'истощения'),\n",
              " Substring(1573, 1574, ','),\n",
              " Substring(1575, 1576, 'а'),\n",
              " Substring(1577, 1582, 'тогда'),\n",
              " Substring(1582, 1583, '…'),\n",
              " Substring(1584, 1588, 'хоть'),\n",
              " Substring(1589, 1592, 'его'),\n",
              " Substring(1593, 1594, 'и'),\n",
              " Substring(1595, 1601, 'трудно'),\n",
              " Substring(1602, 1607, 'убить'),\n",
              " Substring(1607, 1608, ','),\n",
              " Substring(1609, 1616, 'горгоны'),\n",
              " Substring(1617, 1623, 'найдут'),\n",
              " Substring(1624, 1630, 'способ'),\n",
              " Substring(1630, 1631, '.'),\n",
              " Substring(1632, 1634, 'Он'),\n",
              " Substring(1635, 1636, 'в'),\n",
              " Substring(1637, 1641, 'этом'),\n",
              " Substring(1642, 1644, 'не'),\n",
              " Substring(1645, 1655, 'сомневался'),\n",
              " Substring(1655, 1656, '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_tok_text]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjNii1IlQcid",
        "outputId": "0d034987-abee-4a29-d7ab-54b377261ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Дмитрий',\n",
              " 'Иванович',\n",
              " 'Менделеев',\n",
              " 'родился',\n",
              " '27',\n",
              " 'января',\n",
              " '(',\n",
              " '8',\n",
              " 'февраля',\n",
              " ')',\n",
              " '1834',\n",
              " 'года',\n",
              " 'в',\n",
              " 'Тобольске',\n",
              " 'в',\n",
              " 'семье',\n",
              " 'Ивана',\n",
              " 'Павловича',\n",
              " 'Менделеева',\n",
              " ',',\n",
              " 'в',\n",
              " 'то',\n",
              " 'время',\n",
              " 'занимавшего',\n",
              " 'должность',\n",
              " 'директора',\n",
              " 'Тобольской',\n",
              " 'гимназии',\n",
              " 'и',\n",
              " 'училищ',\n",
              " 'Тобольского',\n",
              " 'округа',\n",
              " ',',\n",
              " 'и',\n",
              " 'Марии',\n",
              " 'Дмитриевны',\n",
              " 'Менделеевой',\n",
              " '(',\n",
              " 'Корнильевой',\n",
              " ')',\n",
              " '.',\n",
              " 'Эти',\n",
              " 'змееволосые',\n",
              " 'дамочки',\n",
              " 'уже',\n",
              " 'начали',\n",
              " 'раздражать',\n",
              " 'Перси',\n",
              " '.',\n",
              " 'Они',\n",
              " 'должны',\n",
              " 'были',\n",
              " 'умереть',\n",
              " 'еще',\n",
              " 'три',\n",
              " 'дня',\n",
              " 'назад',\n",
              " ',',\n",
              " 'когда',\n",
              " 'он',\n",
              " 'сбросил',\n",
              " 'на',\n",
              " 'них',\n",
              " 'ящик',\n",
              " 'с',\n",
              " 'шарами',\n",
              " 'для',\n",
              " 'боулинга',\n",
              " 'в',\n",
              " '«',\n",
              " 'Баргин-Марте',\n",
              " '»',\n",
              " 'в',\n",
              " 'Напе',\n",
              " '.',\n",
              " 'Они',\n",
              " 'должны',\n",
              " 'были',\n",
              " 'отдать',\n",
              " 'концы',\n",
              " 'два',\n",
              " 'дня',\n",
              " 'назад',\n",
              " ',',\n",
              " 'после',\n",
              " 'того',\n",
              " 'как',\n",
              " 'он',\n",
              " 'переехал',\n",
              " 'их',\n",
              " 'полицейским',\n",
              " 'автомобилем',\n",
              " 'в',\n",
              " 'Мартинесе',\n",
              " '.',\n",
              " 'И',\n",
              " 'уж',\n",
              " 'точно',\n",
              " 'они',\n",
              " 'должны',\n",
              " 'были',\n",
              " 'сдохнуть',\n",
              " ',',\n",
              " 'когда',\n",
              " 'он',\n",
              " 'отрезал',\n",
              " 'им',\n",
              " 'головы',\n",
              " 'сегодня',\n",
              " 'утром',\n",
              " 'в',\n",
              " 'Тилден-парке',\n",
              " '.',\n",
              " 'Перси',\n",
              " 'убивал',\n",
              " 'их',\n",
              " 'и',\n",
              " 'своими',\n",
              " 'глазами',\n",
              " 'видел',\n",
              " ',',\n",
              " 'как',\n",
              " 'они',\n",
              " 'обращаются',\n",
              " 'в',\n",
              " 'прах',\n",
              " ',',\n",
              " 'но',\n",
              " 'эти',\n",
              " 'гнусные',\n",
              " 'тетки',\n",
              " 'неизменно',\n",
              " 'возвращались',\n",
              " 'к',\n",
              " 'жизни',\n",
              " '.',\n",
              " 'Он',\n",
              " ',',\n",
              " 'похоже',\n",
              " ',',\n",
              " 'даже',\n",
              " 'не',\n",
              " 'мог',\n",
              " 'надолго',\n",
              " 'от',\n",
              " 'них',\n",
              " 'оторваться',\n",
              " '.',\n",
              " 'Он',\n",
              " 'взобрался',\n",
              " 'на',\n",
              " 'вершину',\n",
              " 'холма',\n",
              " 'и',\n",
              " 'перевел',\n",
              " 'дух',\n",
              " '.',\n",
              " 'Сколько',\n",
              " 'времени',\n",
              " 'прошло',\n",
              " 'с',\n",
              " 'тех',\n",
              " 'пор',\n",
              " ',',\n",
              " 'как',\n",
              " 'он',\n",
              " 'прикончил',\n",
              " 'их',\n",
              " 'в',\n",
              " 'последний',\n",
              " 'раз',\n",
              " '?',\n",
              " 'Часа',\n",
              " 'два',\n",
              " ',',\n",
              " 'наверное',\n",
              " '.',\n",
              " 'Кажется',\n",
              " ',',\n",
              " 'они',\n",
              " 'теперь',\n",
              " 'не',\n",
              " 'умирают',\n",
              " 'больше',\n",
              " 'чем',\n",
              " 'на',\n",
              " 'два',\n",
              " 'часа',\n",
              " '…',\n",
              " 'В',\n",
              " 'последние',\n",
              " 'дни',\n",
              " 'Перси',\n",
              " 'почти',\n",
              " 'не',\n",
              " 'спал',\n",
              " '.',\n",
              " 'Ел',\n",
              " 'он',\n",
              " 'то',\n",
              " ',',\n",
              " 'что',\n",
              " 'удавалось',\n",
              " 'стянуть',\n",
              " 'по',\n",
              " 'дороге',\n",
              " ',',\n",
              " '–',\n",
              " 'жевательную',\n",
              " 'конфету',\n",
              " 'из',\n",
              " 'торгового',\n",
              " 'автомата',\n",
              " ',',\n",
              " 'черствый',\n",
              " 'бублик',\n",
              " 'или',\n",
              " 'лепешку',\n",
              " 'буррито',\n",
              " ',',\n",
              " 'хотя',\n",
              " 'прежде',\n",
              " 'он',\n",
              " 'еще',\n",
              " 'так',\n",
              " 'низко',\n",
              " 'не',\n",
              " 'опускался',\n",
              " '.',\n",
              " 'Одежда',\n",
              " 'его',\n",
              " 'порвалась',\n",
              " ',',\n",
              " 'местами',\n",
              " 'обгорела',\n",
              " 'и',\n",
              " 'вся',\n",
              " 'была',\n",
              " 'заляпана',\n",
              " 'слюной',\n",
              " 'монстров',\n",
              " '.',\n",
              " 'Перси',\n",
              " 'до',\n",
              " 'сих',\n",
              " 'пор',\n",
              " 'был',\n",
              " 'жив',\n",
              " 'только',\n",
              " 'потому',\n",
              " ',',\n",
              " 'что',\n",
              " 'две',\n",
              " 'змееволосые',\n",
              " 'дамочки',\n",
              " '(',\n",
              " 'они',\n",
              " 'называли',\n",
              " 'себя',\n",
              " 'горгонами',\n",
              " ')',\n",
              " 'тоже',\n",
              " ',',\n",
              " 'похоже',\n",
              " ',',\n",
              " 'оказались',\n",
              " 'не',\n",
              " 'в',\n",
              " 'состоянии',\n",
              " 'его',\n",
              " 'убить',\n",
              " '.',\n",
              " 'Их',\n",
              " 'когти',\n",
              " 'не',\n",
              " 'оставляли',\n",
              " 'следа',\n",
              " 'на',\n",
              " 'его',\n",
              " 'коже',\n",
              " '.',\n",
              " 'Если',\n",
              " 'они',\n",
              " 'пытались',\n",
              " 'его',\n",
              " 'укусить',\n",
              " '–',\n",
              " 'зубы',\n",
              " 'у',\n",
              " 'них',\n",
              " 'ломались',\n",
              " '.',\n",
              " 'Но',\n",
              " 'Перси',\n",
              " 'уже',\n",
              " 'был',\n",
              " 'на',\n",
              " 'пределе',\n",
              " '.',\n",
              " 'Скоро',\n",
              " 'он',\n",
              " 'свалится',\n",
              " 'от',\n",
              " 'истощения',\n",
              " ',',\n",
              " 'а',\n",
              " 'тогда',\n",
              " '…',\n",
              " 'хоть',\n",
              " 'его',\n",
              " 'и',\n",
              " 'трудно',\n",
              " 'убить',\n",
              " ',',\n",
              " 'горгоны',\n",
              " 'найдут',\n",
              " 'способ',\n",
              " '.',\n",
              " 'Он',\n",
              " 'в',\n",
              " 'этом',\n",
              " 'не',\n",
              " 'сомневался',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_text = list(sentenize(text))\n",
        "n_sen_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixSJ1ERPQqt2",
        "outputId": "f1e07d67-344c-4d18-82df-3db44fffebf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0,\n",
              "           304,\n",
              "           'Дмитрий\\xa0Иванович\\xa0Менделеев\\xa0родился\\xa027\\xa0января\\xa0(8\\xa0февраля)\\xa01834\\xa0года\\xa0в\\xa0Тобольске\\xa0в\\xa0семье\\xa0Ивана\\xa0Павловича\\xa0Менделеева,\\xa0в\\xa0то\\xa0время\\xa0занимавшего\\xa0должность\\xa0директора\\xa0Тобольской\\xa0гимназии\\xa0и\\xa0училищ\\xa0Тобольского\\xa0округа,\\xa0и\\xa0Марии\\xa0Дмитриевны\\xa0Менделеевой\\xa0(Корнильевой).Эти змееволосые дамочки уже начали раздражать Перси.'),\n",
              " Substring(305,\n",
              "           423,\n",
              "           'Они должны были умереть еще три дня назад, когда он сбросил на них ящик с шарами для боулинга в «Баргин-Марте» в Напе.'),\n",
              " Substring(424,\n",
              "           534,\n",
              "           'Они должны были отдать концы два дня назад, после того как он переехал их полицейским автомобилем в Мартинесе.'),\n",
              " Substring(535,\n",
              "           628,\n",
              "           'И уж точно они должны были сдохнуть, когда он отрезал им головы сегодня утром в Тилден-парке.'),\n",
              " Substring(629,\n",
              "           748,\n",
              "           'Перси убивал их и своими глазами видел, как они обращаются в прах, но эти гнусные тетки неизменно возвращались к жизни.'),\n",
              " Substring(749, 799, 'Он, похоже, даже не мог надолго от них оторваться.'),\n",
              " Substring(800, 844, 'Он взобрался на вершину холма и перевел дух.'),\n",
              " Substring(845,\n",
              "           915,\n",
              "           'Сколько времени прошло с тех пор, как он прикончил их в последний раз?'),\n",
              " Substring(916, 935, 'Часа два, наверное.'),\n",
              " Substring(936, 990, 'Кажется, они теперь не умирают больше чем на два часа…'),\n",
              " Substring(991, 1027, 'В последние дни Перси почти не спал.'),\n",
              " Substring(1028,\n",
              "           1195,\n",
              "           'Ел он то, что удавалось стянуть по дороге, – жевательную конфету из торгового автомата, черствый бублик или лепешку буррито, хотя прежде он еще так низко не опускался.'),\n",
              " Substring(1196,\n",
              "           1271,\n",
              "           'Одежда его порвалась, местами обгорела и вся была заляпана слюной монстров.'),\n",
              " Substring(1272,\n",
              "           1419,\n",
              "           'Перси до сих пор был жив только потому, что две змееволосые дамочки (они называли себя горгонами) тоже, похоже, оказались не в состоянии его убить.'),\n",
              " Substring(1420, 1460, 'Их когти не оставляли следа на его коже.'),\n",
              " Substring(1461, 1513, 'Если они пытались его укусить – зубы у них ломались.'),\n",
              " Substring(1514, 1542, 'Но Перси уже был на пределе.'),\n",
              " Substring(1543,\n",
              "           1631,\n",
              "           'Скоро он свалится от истощения, а тогда… хоть его и трудно убить, горгоны найдут способ.'),\n",
              " Substring(1632, 1656, 'Он в этом не сомневался.')]"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svQYbaCWQriq",
        "outputId": "2eae0808-7a26-4da3-a5b1-4426e4db26fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Дмитрий\\xa0Иванович\\xa0Менделеев\\xa0родился\\xa027\\xa0января\\xa0(8\\xa0февраля)\\xa01834\\xa0года\\xa0в\\xa0Тобольске\\xa0в\\xa0семье\\xa0Ивана\\xa0Павловича\\xa0Менделеева,\\xa0в\\xa0то\\xa0время\\xa0занимавшего\\xa0должность\\xa0директора\\xa0Тобольской\\xa0гимназии\\xa0и\\xa0училищ\\xa0Тобольского\\xa0округа,\\xa0и\\xa0Марии\\xa0Дмитриевны\\xa0Менделеевой\\xa0(Корнильевой).Эти змееволосые дамочки уже начали раздражать Перси.',\n",
              "  'Они должны были умереть еще три дня назад, когда он сбросил на них ящик с шарами для боулинга в «Баргин-Марте» в Напе.',\n",
              "  'Они должны были отдать концы два дня назад, после того как он переехал их полицейским автомобилем в Мартинесе.',\n",
              "  'И уж точно они должны были сдохнуть, когда он отрезал им головы сегодня утром в Тилден-парке.',\n",
              "  'Перси убивал их и своими глазами видел, как они обращаются в прах, но эти гнусные тетки неизменно возвращались к жизни.',\n",
              "  'Он, похоже, даже не мог надолго от них оторваться.',\n",
              "  'Он взобрался на вершину холма и перевел дух.',\n",
              "  'Сколько времени прошло с тех пор, как он прикончил их в последний раз?',\n",
              "  'Часа два, наверное.',\n",
              "  'Кажется, они теперь не умирают больше чем на два часа…',\n",
              "  'В последние дни Перси почти не спал.',\n",
              "  'Ел он то, что удавалось стянуть по дороге, – жевательную конфету из торгового автомата, черствый бублик или лепешку буррито, хотя прежде он еще так низко не опускался.',\n",
              "  'Одежда его порвалась, местами обгорела и вся была заляпана слюной монстров.',\n",
              "  'Перси до сих пор был жив только потому, что две змееволосые дамочки (они называли себя горгонами) тоже, похоже, оказались не в состоянии его убить.',\n",
              "  'Их когти не оставляли следа на его коже.',\n",
              "  'Если они пытались его укусить – зубы у них ломались.',\n",
              "  'Но Перси уже был на пределе.',\n",
              "  'Скоро он свалится от истощения, а тогда… хоть его и трудно убить, горгоны найдут способ.',\n",
              "  'Он в этом не сомневался.'],\n",
              " 19)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот вариант токенизации нужен для последующей обработки\n",
        "def n_sentenize(text):\n",
        "    n_sen_chunk = []\n",
        "    for sent in sentenize(text):\n",
        "        tokens = [_.text for _ in tokenize(sent.text)]\n",
        "        n_sen_chunk.append(tokens)\n",
        "    return n_sen_chunk"
      ],
      "metadata": {
        "id": "78LQGe5NQy5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk = n_sentenize(text)\n",
        "n_sen_chunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSFbNwwbQz1v",
        "outputId": "b0802cbb-fc85-4521-926e-63aca1a76171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Дмитрий',\n",
              "  'Иванович',\n",
              "  'Менделеев',\n",
              "  'родился',\n",
              "  '27',\n",
              "  'января',\n",
              "  '(',\n",
              "  '8',\n",
              "  'февраля',\n",
              "  ')',\n",
              "  '1834',\n",
              "  'года',\n",
              "  'в',\n",
              "  'Тобольске',\n",
              "  'в',\n",
              "  'семье',\n",
              "  'Ивана',\n",
              "  'Павловича',\n",
              "  'Менделеева',\n",
              "  ',',\n",
              "  'в',\n",
              "  'то',\n",
              "  'время',\n",
              "  'занимавшего',\n",
              "  'должность',\n",
              "  'директора',\n",
              "  'Тобольской',\n",
              "  'гимназии',\n",
              "  'и',\n",
              "  'училищ',\n",
              "  'Тобольского',\n",
              "  'округа',\n",
              "  ',',\n",
              "  'и',\n",
              "  'Марии',\n",
              "  'Дмитриевны',\n",
              "  'Менделеевой',\n",
              "  '(',\n",
              "  'Корнильевой',\n",
              "  ')',\n",
              "  '.',\n",
              "  'Эти',\n",
              "  'змееволосые',\n",
              "  'дамочки',\n",
              "  'уже',\n",
              "  'начали',\n",
              "  'раздражать',\n",
              "  'Перси',\n",
              "  '.'],\n",
              " ['Они',\n",
              "  'должны',\n",
              "  'были',\n",
              "  'умереть',\n",
              "  'еще',\n",
              "  'три',\n",
              "  'дня',\n",
              "  'назад',\n",
              "  ',',\n",
              "  'когда',\n",
              "  'он',\n",
              "  'сбросил',\n",
              "  'на',\n",
              "  'них',\n",
              "  'ящик',\n",
              "  'с',\n",
              "  'шарами',\n",
              "  'для',\n",
              "  'боулинга',\n",
              "  'в',\n",
              "  '«',\n",
              "  'Баргин-Марте',\n",
              "  '»',\n",
              "  'в',\n",
              "  'Напе',\n",
              "  '.'],\n",
              " ['Они',\n",
              "  'должны',\n",
              "  'были',\n",
              "  'отдать',\n",
              "  'концы',\n",
              "  'два',\n",
              "  'дня',\n",
              "  'назад',\n",
              "  ',',\n",
              "  'после',\n",
              "  'того',\n",
              "  'как',\n",
              "  'он',\n",
              "  'переехал',\n",
              "  'их',\n",
              "  'полицейским',\n",
              "  'автомобилем',\n",
              "  'в',\n",
              "  'Мартинесе',\n",
              "  '.'],\n",
              " ['И',\n",
              "  'уж',\n",
              "  'точно',\n",
              "  'они',\n",
              "  'должны',\n",
              "  'были',\n",
              "  'сдохнуть',\n",
              "  ',',\n",
              "  'когда',\n",
              "  'он',\n",
              "  'отрезал',\n",
              "  'им',\n",
              "  'головы',\n",
              "  'сегодня',\n",
              "  'утром',\n",
              "  'в',\n",
              "  'Тилден-парке',\n",
              "  '.'],\n",
              " ['Перси',\n",
              "  'убивал',\n",
              "  'их',\n",
              "  'и',\n",
              "  'своими',\n",
              "  'глазами',\n",
              "  'видел',\n",
              "  ',',\n",
              "  'как',\n",
              "  'они',\n",
              "  'обращаются',\n",
              "  'в',\n",
              "  'прах',\n",
              "  ',',\n",
              "  'но',\n",
              "  'эти',\n",
              "  'гнусные',\n",
              "  'тетки',\n",
              "  'неизменно',\n",
              "  'возвращались',\n",
              "  'к',\n",
              "  'жизни',\n",
              "  '.'],\n",
              " ['Он',\n",
              "  ',',\n",
              "  'похоже',\n",
              "  ',',\n",
              "  'даже',\n",
              "  'не',\n",
              "  'мог',\n",
              "  'надолго',\n",
              "  'от',\n",
              "  'них',\n",
              "  'оторваться',\n",
              "  '.'],\n",
              " ['Он', 'взобрался', 'на', 'вершину', 'холма', 'и', 'перевел', 'дух', '.'],\n",
              " ['Сколько',\n",
              "  'времени',\n",
              "  'прошло',\n",
              "  'с',\n",
              "  'тех',\n",
              "  'пор',\n",
              "  ',',\n",
              "  'как',\n",
              "  'он',\n",
              "  'прикончил',\n",
              "  'их',\n",
              "  'в',\n",
              "  'последний',\n",
              "  'раз',\n",
              "  '?'],\n",
              " ['Часа', 'два', ',', 'наверное', '.'],\n",
              " ['Кажется',\n",
              "  ',',\n",
              "  'они',\n",
              "  'теперь',\n",
              "  'не',\n",
              "  'умирают',\n",
              "  'больше',\n",
              "  'чем',\n",
              "  'на',\n",
              "  'два',\n",
              "  'часа',\n",
              "  '…'],\n",
              " ['В', 'последние', 'дни', 'Перси', 'почти', 'не', 'спал', '.'],\n",
              " ['Ел',\n",
              "  'он',\n",
              "  'то',\n",
              "  ',',\n",
              "  'что',\n",
              "  'удавалось',\n",
              "  'стянуть',\n",
              "  'по',\n",
              "  'дороге',\n",
              "  ',',\n",
              "  '–',\n",
              "  'жевательную',\n",
              "  'конфету',\n",
              "  'из',\n",
              "  'торгового',\n",
              "  'автомата',\n",
              "  ',',\n",
              "  'черствый',\n",
              "  'бублик',\n",
              "  'или',\n",
              "  'лепешку',\n",
              "  'буррито',\n",
              "  ',',\n",
              "  'хотя',\n",
              "  'прежде',\n",
              "  'он',\n",
              "  'еще',\n",
              "  'так',\n",
              "  'низко',\n",
              "  'не',\n",
              "  'опускался',\n",
              "  '.'],\n",
              " ['Одежда',\n",
              "  'его',\n",
              "  'порвалась',\n",
              "  ',',\n",
              "  'местами',\n",
              "  'обгорела',\n",
              "  'и',\n",
              "  'вся',\n",
              "  'была',\n",
              "  'заляпана',\n",
              "  'слюной',\n",
              "  'монстров',\n",
              "  '.'],\n",
              " ['Перси',\n",
              "  'до',\n",
              "  'сих',\n",
              "  'пор',\n",
              "  'был',\n",
              "  'жив',\n",
              "  'только',\n",
              "  'потому',\n",
              "  ',',\n",
              "  'что',\n",
              "  'две',\n",
              "  'змееволосые',\n",
              "  'дамочки',\n",
              "  '(',\n",
              "  'они',\n",
              "  'называли',\n",
              "  'себя',\n",
              "  'горгонами',\n",
              "  ')',\n",
              "  'тоже',\n",
              "  ',',\n",
              "  'похоже',\n",
              "  ',',\n",
              "  'оказались',\n",
              "  'не',\n",
              "  'в',\n",
              "  'состоянии',\n",
              "  'его',\n",
              "  'убить',\n",
              "  '.'],\n",
              " ['Их', 'когти', 'не', 'оставляли', 'следа', 'на', 'его', 'коже', '.'],\n",
              " ['Если',\n",
              "  'они',\n",
              "  'пытались',\n",
              "  'его',\n",
              "  'укусить',\n",
              "  '–',\n",
              "  'зубы',\n",
              "  'у',\n",
              "  'них',\n",
              "  'ломались',\n",
              "  '.'],\n",
              " ['Но', 'Перси', 'уже', 'был', 'на', 'пределе', '.'],\n",
              " ['Скоро',\n",
              "  'он',\n",
              "  'свалится',\n",
              "  'от',\n",
              "  'истощения',\n",
              "  ',',\n",
              "  'а',\n",
              "  'тогда',\n",
              "  '…',\n",
              "  'хоть',\n",
              "  'его',\n",
              "  'и',\n",
              "  'трудно',\n",
              "  'убить',\n",
              "  ',',\n",
              "  'горгоны',\n",
              "  'найдут',\n",
              "  'способ',\n",
              "  '.'],\n",
              " ['Он', 'в', 'этом', 'не', 'сомневался', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_sen_chunk_2 = n_sentenize(text2)\n",
        "n_sen_chunk_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFh2bRXUQ6LE",
        "outputId": "16e59467-9cb3-42cc-aace-803773ca9d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['МГТУ',\n",
              "  'им',\n",
              "  '.',\n",
              "  'Н',\n",
              "  '.',\n",
              "  'Э',\n",
              "  '.',\n",
              "  'Ба́умана',\n",
              "  '—',\n",
              "  'российский',\n",
              "  'национальный',\n",
              "  'исследовательский',\n",
              "  'университет',\n",
              "  ',',\n",
              "  'Предыдущее',\n",
              "  'название',\n",
              "  'университета',\n",
              "  '«',\n",
              "  'Моско́вское',\n",
              "  'вы́сшее',\n",
              "  'техни́ческое',\n",
              "  'учи́лище',\n",
              "  'им',\n",
              "  '.',\n",
              "  'Н',\n",
              "  '.',\n",
              "  'Э',\n",
              "  '.',\n",
              "  'Ба́умана',\n",
              "  '»',\n",
              "  'было',\n",
              "  'присвоено',\n",
              "  'ему',\n",
              "  'в',\n",
              "  'честь',\n",
              "  'революционера',\n",
              "  'Николая',\n",
              "  'Эрнестовича',\n",
              "  'Баумана',\n",
              "  ',']]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Частеричная разметка (Part-Of-Speech tagging, POS-tagging)"
      ],
      "metadata": {
        "id": "Uscgyimj6LWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В некоторых библиотеках вначале выполняется частеречная разметка, а далее на ее основе выполняется лемматизация."
      ],
      "metadata": {
        "id": "nzmwOM0RqNtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "yOzIUkJzqTBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JGUPQbFLrOJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "spacy_test = nlp(test_text)\n",
        "# from spacy.lang.ru import Russian\n",
        "# import spacy\n",
        "# nlp = spacy.load('ru_core_news_sm')\n",
        "# spacy_text = nlp(test_text)\n",
        "# spacy_text"
      ],
      "metadata": {
        "id": "kfuCP4tr6SQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Просмотрим какие части речи присутсвуют в тестовом твите:"
      ],
      "metadata": {
        "id": "sNKuPH--6H_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in spacy_test:\n",
        "    print('{} - {} - {}'.format(token.text, token.pos_, token.dep_))"
      ],
      "metadata": {
        "id": "ZTfrFTBT6VIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8893d0db-b470-4979-acaa-542cd27ecc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Праздник - PROPN - compound\n",
            "весны - VERB - compound\n",
            "является - ADJ - compound\n",
            "самым - PROPN - compound\n",
            "любимым - VERB - compound\n",
            "праздником - NOUN - compound\n",
            "китайцев - PROPN - ROOT\n",
            ".Накануне - PUNCT - punct\n",
            "его - PROPN - compound\n",
            "китайцы - NOUN - nsubj\n",
            ", - PUNCT - punct\n",
            "которые - PROPN - ROOT\n",
            "　 - SPACE - \n",
            "рабатают - PROPN - nsubj\n",
            "или - PROPN - ccomp\n",
            "занимаются - ADV - amod\n",
            "в - PROPN - compound\n",
            "других - NOUN - compound\n",
            "местах - ADJ - dobj\n",
            ", - PUNCT - punct\n",
            "несмотря - PROPN - compound\n",
            "на - PROPN - compound\n",
            "далёкий - PROPN - compound\n",
            "путь - PROPN - conj\n",
            ", - PUNCT - punct\n",
            "всегда - NOUN - compound\n",
            "спешат - NOUN - compound\n",
            "к - PROPN - compound\n",
            "родным - NOUN - compound\n",
            "очагам - PROPN - conj\n",
            ", - PUNCT - punct\n",
            "чтобы - PROPN - compound\n",
            "провести - PROPN - nsubj\n",
            "этот - VERB - conj\n",
            "праздник - PROPN - compound\n",
            "дома - PROPN - dobj\n",
            ", - PUNCT - punct\n",
            "со - PROPN - intj\n",
            "своими - PROPN - compound\n",
            "близкими - PROPN - appos\n",
            ". - PUNCT - punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "v1dpbny7uJVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from navec import Navec\n",
        "from slovnet import Morph"
      ],
      "metadata": {
        "id": "dWlwA9EjQ-Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
        "navec = Navec.load('/content/navec_news_v1_1B_250K_300d_100q (1).tar')"
      ],
      "metadata": {
        "id": "A56s0v6KREM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
        "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
      ],
      "metadata": {
        "id": "8URHHeoERExt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_res = n_morph.navec(navec)"
      ],
      "metadata": {
        "id": "8OekmhyiRNit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pos(markup):\n",
        "    for token in markup.tokens:\n",
        "        print('{} - {}'.format(token.text, token.tag))"
      ],
      "metadata": {
        "id": "5QYBE8gORYS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
        "[print_pos(x) for x in n_text_markup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlv5OaGGRY0H",
        "outputId": "9ee6bfac-95fd-4b9e-f913-ee65ad32a902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дмитрий - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "Иванович - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "Менделеев - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "родился - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "27 - ADJ\n",
            "января - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "( - PUNCT\n",
            "8 - ADJ\n",
            "февраля - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            ") - PUNCT\n",
            "1834 - ADJ\n",
            "года - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "Тобольске - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "семье - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            "Ивана - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "Павловича - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "Менделеева - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "в - ADP\n",
            "то - DET|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            "время - NOUN|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            "занимавшего - VERB|Animacy=Anim|Aspect=Imp|Case=Acc|Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part|Voice=Act\n",
            "должность - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "директора - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "Тобольской - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
            "гимназии - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
            "и - CCONJ\n",
            "училищ - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur\n",
            "Тобольского - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
            "округа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "и - CCONJ\n",
            "Марии - PROPN|Animacy=Anim|Case=Gen|Gender=Fem|Number=Sing\n",
            "Дмитриевны - PROPN|Animacy=Anim|Case=Gen|Gender=Fem|Number=Sing\n",
            "Менделеевой - PROPN|Animacy=Anim|Case=Gen|Gender=Fem|Number=Sing\n",
            "( - PUNCT\n",
            "Корнильевой - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            ") - PUNCT\n",
            ". - PUNCT\n",
            "Эти - DET|Case=Nom|Number=Plur\n",
            "змееволосые - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            "дамочки - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "уже - ADV|Degree=Pos\n",
            "начали - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "раздражать - VERB|Aspect=Imp|VerbForm=Inf|Voice=Act\n",
            "Перси - PROPN|Animacy=Anim|Case=Acc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "должны - ADJ|Degree=Pos|Number=Plur|Variant=Short\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "умереть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "еще - ADV|Degree=Pos\n",
            "три - NUM|Animacy=Inan|Case=Acc\n",
            "дня - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "назад - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "когда - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "сбросил - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "на - ADP\n",
            "них - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "ящик - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "с - ADP\n",
            "шарами - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Plur\n",
            "для - ADP\n",
            "боулинга - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "« - PUNCT\n",
            "Баргин-Марте - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            "» - PUNCT\n",
            "в - ADP\n",
            "Напе - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "должны - ADJ|Degree=Pos|Number=Plur|Variant=Short\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "отдать - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "концы - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            "два - NUM|Animacy=Inan|Case=Acc|Gender=Masc\n",
            "дня - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "назад - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "после - ADP\n",
            "того - PRON|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "как - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "переехал - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "их - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "полицейским - ADJ|Case=Ins|Degree=Pos|Gender=Masc|Number=Sing\n",
            "автомобилем - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            "в - ADP\n",
            "Мартинесе - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "И - CCONJ\n",
            "уж - PART\n",
            "точно - ADV|Degree=Pos\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "должны - ADJ|Degree=Pos|Number=Plur|Variant=Short\n",
            "были - AUX|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "сдохнуть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            ", - PUNCT\n",
            "когда - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "отрезал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "им - PRON|Case=Dat|Number=Plur|Person=3\n",
            "головы - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur\n",
            "сегодня - ADV|Degree=Pos\n",
            "утром - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing\n",
            "в - ADP\n",
            "Тилден-парке - PROPN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "убивал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "их - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "и - CCONJ\n",
            "своими - DET|Case=Ins|Number=Plur\n",
            "глазами - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Plur\n",
            "видел - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ", - PUNCT\n",
            "как - SCONJ\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "обращаются - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            "в - ADP\n",
            "прах - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "но - CCONJ\n",
            "эти - DET|Case=Nom|Number=Plur\n",
            "гнусные - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            "тетки - NOUN|Animacy=Anim|Case=Nom|Gender=Fem|Number=Plur\n",
            "неизменно - ADV|Degree=Pos\n",
            "возвращались - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "к - ADP\n",
            "жизни - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n",
            "Он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            ", - PUNCT\n",
            "похоже - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "даже - PART\n",
            "не - PART|Polarity=Neg\n",
            "мог - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "надолго - ADV|Degree=Pos\n",
            "от - ADP\n",
            "них - PRON|Case=Gen|Number=Plur|Person=3\n",
            "оторваться - VERB|Aspect=Perf|VerbForm=Inf|Voice=Mid\n",
            ". - PUNCT\n",
            "Он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "взобрался - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "на - ADP\n",
            "вершину - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "холма - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "и - CCONJ\n",
            "перевел - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "дух - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Сколько - NUM|Animacy=Inan|Case=Acc\n",
            "времени - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "прошло - VERB|Aspect=Perf|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "с - ADP\n",
            "тех - DET|Case=Gen|Number=Plur\n",
            "пор - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
            ", - PUNCT\n",
            "как - SCONJ\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "прикончил - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "их - PRON|Animacy=Inan|Case=Acc|Number=Plur|Person=3\n",
            "в - ADP\n",
            "последний - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\n",
            "раз - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "? - PUNCT\n",
            "Часа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "два - NUM|Case=Nom|Gender=Masc\n",
            ", - PUNCT\n",
            "наверное - ADV|Degree=Pos\n",
            ". - PUNCT\n",
            "Кажется - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid\n",
            ", - PUNCT\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "теперь - ADV|Degree=Pos\n",
            "не - PART|Polarity=Neg\n",
            "умирают - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
            "больше - ADV|Degree=Cmp\n",
            "чем - SCONJ\n",
            "на - ADP\n",
            "два - NUM|Animacy=Inan|Case=Acc|Gender=Masc\n",
            "часа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "… - PUNCT\n",
            "В - ADP\n",
            "последние - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Number=Plur\n",
            "дни - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Plur\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "почти - ADV|Degree=Pos\n",
            "не - PART|Polarity=Neg\n",
            "спал - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ". - PUNCT\n",
            "Ел - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "то - PRON|Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing\n",
            ", - PUNCT\n",
            "что - SCONJ\n",
            "удавалось - VERB|Aspect=Imp|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "стянуть - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "по - ADP\n",
            "дороге - NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\n",
            ", - PUNCT\n",
            "– - PUNCT\n",
            "жевательную - ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
            "конфету - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "из - ADP\n",
            "торгового - ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
            "автомата - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "черствый - VERB|Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "бублик - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            "или - CCONJ\n",
            "лепешку - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "буррито - NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "хотя - SCONJ\n",
            "прежде - ADV|Degree=Pos\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "еще - ADV|Degree=Pos\n",
            "так - ADV|Degree=Pos\n",
            "низко - ADV|Degree=Pos\n",
            "не - PART|Polarity=Neg\n",
            "опускался - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            ". - PUNCT\n",
            "Одежда - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            "его - PRON|Case=Gen|Gender=Masc|Number=Sing|Person=3\n",
            "порвалась - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            ", - PUNCT\n",
            "местами - NOUN|Animacy=Inan|Case=Ins|Gender=Neut|Number=Plur\n",
            "обгорела - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
            "и - CCONJ\n",
            "вся - DET|Case=Nom|Gender=Fem|Number=Sing\n",
            "была - AUX|Aspect=Imp|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "заляпана - VERB|Aspect=Perf|Gender=Fem|Number=Sing|Tense=Past|Variant=Short|VerbForm=Part|Voice=Pass\n",
            "слюной - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
            "монстров - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur\n",
            ". - PUNCT\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "до - ADP\n",
            "сих - DET|Case=Gen|Number=Plur\n",
            "пор - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur\n",
            "был - AUX|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "жив - ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
            "только - PART\n",
            "потому - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "что - SCONJ\n",
            "две - NUM|Case=Nom|Gender=Fem\n",
            "змееволосые - ADJ|Case=Nom|Degree=Pos|Number=Plur\n",
            "дамочки - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "( - PUNCT\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "называли - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "себя - PRON|Case=Acc\n",
            "горгонами - NOUN|Animacy=Anim|Case=Ins|Gender=Masc|Number=Plur\n",
            ") - PUNCT\n",
            "тоже - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "похоже - ADV|Degree=Pos\n",
            ", - PUNCT\n",
            "оказались - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "не - PART|Polarity=Neg\n",
            "в - ADP\n",
            "состоянии - NOUN|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "его - PRON|Case=Acc|Gender=Masc|Number=Sing|Person=3\n",
            "убить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            ". - PUNCT\n",
            "Их - DET\n",
            "когти - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "не - PART|Polarity=Neg\n",
            "оставляли - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "следа - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "на - ADP\n",
            "его - DET\n",
            "коже - NOUN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
            ". - PUNCT\n",
            "Если - SCONJ\n",
            "они - PRON|Case=Nom|Number=Plur|Person=3\n",
            "пытались - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            "его - PRON|Case=Acc|Gender=Masc|Number=Sing|Person=3\n",
            "укусить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            "– - PUNCT\n",
            "зубы - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur\n",
            "у - ADP\n",
            "них - PRON|Case=Gen|Number=Plur|Person=3\n",
            "ломались - VERB|Aspect=Imp|Mood=Ind|Number=Plur|Tense=Past|VerbForm=Fin|Voice=Act\n",
            ". - PUNCT\n",
            "Но - CCONJ\n",
            "Перси - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "уже - ADV|Degree=Pos\n",
            "был - AUX|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "на - ADP\n",
            "пределе - NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Скоро - ADV|Degree=Pos\n",
            "он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "свалится - VERB|Aspect=Perf|Mood=Ind|Number=Sing|Person=3|Tense=Fut|VerbForm=Fin|Voice=Mid\n",
            "от - ADP\n",
            "истощения - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            ", - PUNCT\n",
            "а - CCONJ\n",
            "тогда - ADV|Degree=Pos\n",
            "… - PUNCT\n",
            "хоть - ADV|Degree=Pos\n",
            "его - PRON|Case=Acc|Gender=Masc|Number=Sing|Person=3\n",
            "и - CCONJ\n",
            "трудно - ADJ|Degree=Pos|Gender=Neut|Number=Sing|Variant=Short\n",
            "убить - VERB|Aspect=Perf|VerbForm=Inf|Voice=Act\n",
            ", - PUNCT\n",
            "горгоны - NOUN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur\n",
            "найдут - VERB|Aspect=Perf|Mood=Ind|Number=Plur|Person=3|Tense=Fut|VerbForm=Fin|Voice=Act\n",
            "способ - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Он - PRON|Case=Nom|Gender=Masc|Number=Sing|Person=3\n",
            "в - ADP\n",
            "этом - PRON|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
            "не - PART|Polarity=Neg\n",
            "сомневался - VERB|Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid\n",
            ". - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
        "[print_pos(x) for x in n_text2_markup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf1e4LOkRcHI",
        "outputId": "8d7e5f00-a0c3-4f39-ca71-913573e743ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "МГТУ - PROPN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            "им - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
            ". - PUNCT\n",
            "Н - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Э - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Ба́умана - PROPN|Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing\n",
            "— - PUNCT\n",
            "российский - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "национальный - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "исследовательский - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "университет - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n",
            "Предыдущее - ADJ|Case=Nom|Degree=Pos|Gender=Neut|Number=Sing\n",
            "название - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
            "университета - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "« - PUNCT\n",
            "Моско́вское - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
            "вы́сшее - X|Foreign=Yes\n",
            "техни́ческое - ADJ|Case=Dat|Degree=Pos|Gender=Masc|Number=Sing\n",
            "учи́лище - NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
            "им - PRON|Case=Ins|Gender=Masc|Number=Sing|Person=3\n",
            ". - PUNCT\n",
            "Н - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Э - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            ". - PUNCT\n",
            "Ба́умана - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "» - PUNCT\n",
            "было - AUX|Aspect=Imp|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\n",
            "присвоено - VERB|Aspect=Perf|Gender=Neut|Number=Sing|Tense=Past|Variant=Short|VerbForm=Part|Voice=Pass\n",
            "ему - PRON|Case=Dat|Gender=Masc|Number=Sing|Person=3\n",
            "в - ADP\n",
            "честь - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
            "революционера - NOUN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "Николая - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "Эрнестовича - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            "Баумана - PROPN|Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing\n",
            ", - PUNCT\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None]"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Лемматизация"
      ],
      "metadata": {
        "id": "eWP6ezDc6aE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "5a-o2y_LvKlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in spacy_test:\n",
        "      print(token, token.lemma, token.lemma_)"
      ],
      "metadata": {
        "id": "bSc_XMaw6dBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bdfad22-3041-426c-949e-e945075d221b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Праздник 1840354460546522912 Праздник\n",
            "весны 14721510421981876170 весны\n",
            "является 11228620018285619923 является\n",
            "самым 131047934457931729 самым\n",
            "любимым 14607805921186229421 любимым\n",
            "праздником 2380343434576960769 праздником\n",
            "китайцев 17453396853267337055 китайцев\n",
            ".Накануне 11641952432637114577 .Накануне\n",
            "его 6166162853077514292 его\n",
            "китайцы 7787469979702150596 китайцы\n",
            ", 2593208677638477497 ,\n",
            "которые 10821169212437491113 которые\n",
            "　 13912603054523871734 　\n",
            "рабатают 12496267239876250009 рабатают\n",
            "или 1530020831762146143 или\n",
            "занимаются 5289187509458912700 занимаются\n",
            "в 15939375860797385675 в\n",
            "других 5568520122224931142 других\n",
            "местах 14922183477643145597 местах\n",
            ", 2593208677638477497 ,\n",
            "несмотря 4313172793392934716 несмотря\n",
            "на 16191904166009283104 на\n",
            "далёкий 6723292147973124723 далёкий\n",
            "путь 10530679371794504240 путь\n",
            ", 2593208677638477497 ,\n",
            "всегда 10633257961924346802 всегда\n",
            "спешат 14656338628323285350 спешат\n",
            "к 2390146911029080849 к\n",
            "родным 18367528641597240676 родным\n",
            "очагам 6535154930049018912 очагам\n",
            ", 2593208677638477497 ,\n",
            "чтобы 10327972121992521358 чтобы\n",
            "провести 5160007530980309479 провести\n",
            "этот 13138259693353519549 этот\n",
            "праздник 8745251629403612823 праздник\n",
            "дома 1579389597620111726 дома\n",
            ", 2593208677638477497 ,\n",
            "со 12039906729841018817 со\n",
            "своими 12718946594216898768 своими\n",
            "близкими 6698017153815111151 близкими\n",
            ". 12646065887601541794 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "zXk8-GBkvF2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
      ],
      "metadata": {
        "id": "FuySXFnRTHLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_lemmatize(text):\n",
        "    emb = NewsEmbedding()\n",
        "    morph_tagger = NewsMorphTagger(emb)\n",
        "    segmenter = Segmenter()\n",
        "    morph_vocab = MorphVocab()\n",
        "    doc = Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.tag_morph(morph_tagger)\n",
        "    for token in doc.tokens:\n",
        "        token.lemmatize(morph_vocab)\n",
        "    return doc"
      ],
      "metadata": {
        "id": "oodcjl3LTJTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc = n_lemmatize(text)\n",
        "{_.text: _.lemma for _ in n_doc.tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzjf5dRGTLag",
        "outputId": "f388b558-6204-45bd-bec1-40e937c30ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(': '(',\n",
              " ')': ')',\n",
              " ',': ',',\n",
              " '.': '.',\n",
              " '1834': '1834',\n",
              " '27': '27',\n",
              " '8': '8',\n",
              " '?': '?',\n",
              " '«': '«',\n",
              " '»': '»',\n",
              " 'Баргин-Марте': 'баргин-марта',\n",
              " 'В': 'в',\n",
              " 'Дмитриевны': 'дмитриевич',\n",
              " 'Дмитрий': 'дмитрий',\n",
              " 'Ел': 'есть',\n",
              " 'Если': 'если',\n",
              " 'И': 'и',\n",
              " 'Ивана': 'иван',\n",
              " 'Иванович': 'иванович',\n",
              " 'Их': 'их',\n",
              " 'Кажется': 'казаться',\n",
              " 'Корнильевой': 'корнильевой',\n",
              " 'Марии': 'мария',\n",
              " 'Мартинесе': 'мартинес',\n",
              " 'Менделеев': 'менделеев',\n",
              " 'Менделеева': 'менделеев',\n",
              " 'Менделеевой': 'менделеев',\n",
              " 'Напе': 'напе',\n",
              " 'Но': 'но',\n",
              " 'Одежда': 'одежда',\n",
              " 'Он': 'он',\n",
              " 'Они': 'они',\n",
              " 'Павловича': 'павлович',\n",
              " 'Перси': 'перси',\n",
              " 'Сколько': 'сколько',\n",
              " 'Скоро': 'скоро',\n",
              " 'Тилден-парке': 'тилден-парк',\n",
              " 'Тобольске': 'тобольск',\n",
              " 'Тобольского': 'тобольский',\n",
              " 'Тобольской': 'тобольский',\n",
              " 'Часа': 'час',\n",
              " 'Эти': 'этот',\n",
              " 'а': 'а',\n",
              " 'автомата': 'автомат',\n",
              " 'автомобилем': 'автомобиль',\n",
              " 'больше': 'большой',\n",
              " 'боулинга': 'боулинг',\n",
              " 'бублик': 'бублик',\n",
              " 'буррито': 'буррито',\n",
              " 'был': 'быть',\n",
              " 'была': 'быть',\n",
              " 'были': 'быть',\n",
              " 'в': 'в',\n",
              " 'вершину': 'вершина',\n",
              " 'взобрался': 'взобраться',\n",
              " 'видел': 'видеть',\n",
              " 'возвращались': 'возвращаться',\n",
              " 'времени': 'время',\n",
              " 'время': 'время',\n",
              " 'вся': 'весь',\n",
              " 'гимназии': 'гимназия',\n",
              " 'глазами': 'глаз',\n",
              " 'гнусные': 'гнусный',\n",
              " 'года': 'год',\n",
              " 'головы': 'голова',\n",
              " 'горгонами': 'горгон',\n",
              " 'горгоны': 'горгон',\n",
              " 'даже': 'даже',\n",
              " 'дамочки': 'дамочка',\n",
              " 'два': 'два',\n",
              " 'две': 'два',\n",
              " 'директора': 'директор',\n",
              " 'для': 'для',\n",
              " 'дни': 'день',\n",
              " 'дня': 'день',\n",
              " 'до': 'до',\n",
              " 'должность': 'должность',\n",
              " 'должны': 'должный',\n",
              " 'дороге': 'дорога',\n",
              " 'дух': 'дух',\n",
              " 'его': 'он',\n",
              " 'еще': 'еще',\n",
              " 'жевательную': 'жевательный',\n",
              " 'жив': 'живой',\n",
              " 'жизни': 'жизнь',\n",
              " 'заляпана': 'заляпать',\n",
              " 'занимавшего': 'занимать',\n",
              " 'змееволосые': 'змееволосый',\n",
              " 'зубы': 'зуб',\n",
              " 'и': 'и',\n",
              " 'из': 'из',\n",
              " 'или': 'или',\n",
              " 'им': 'они',\n",
              " 'истощения': 'истощение',\n",
              " 'их': 'они',\n",
              " 'к': 'к',\n",
              " 'как': 'как',\n",
              " 'когда': 'когда',\n",
              " 'когти': 'коготь',\n",
              " 'коже': 'кожа',\n",
              " 'конфету': 'конфета',\n",
              " 'концы': 'конец',\n",
              " 'лепешку': 'лепешка',\n",
              " 'ломались': 'ломаться',\n",
              " 'местами': 'место',\n",
              " 'мог': 'мочь',\n",
              " 'монстров': 'монстр',\n",
              " 'на': 'на',\n",
              " 'наверное': 'наверное',\n",
              " 'надолго': 'надолго',\n",
              " 'назад': 'назад',\n",
              " 'называли': 'называть',\n",
              " 'найдут': 'найти',\n",
              " 'начали': 'начать',\n",
              " 'не': 'не',\n",
              " 'неизменно': 'неизменно',\n",
              " 'низко': 'низко',\n",
              " 'них': 'они',\n",
              " 'но': 'но',\n",
              " 'обгорела': 'обгореть',\n",
              " 'обращаются': 'обращаться',\n",
              " 'оказались': 'оказаться',\n",
              " 'округа': 'округ',\n",
              " 'он': 'он',\n",
              " 'они': 'они',\n",
              " 'опускался': 'опускаться',\n",
              " 'оставляли': 'оставлять',\n",
              " 'от': 'от',\n",
              " 'отдать': 'отдать',\n",
              " 'оторваться': 'оторваться',\n",
              " 'отрезал': 'отрезать',\n",
              " 'перевел': 'перевести',\n",
              " 'переехал': 'переехать',\n",
              " 'по': 'по',\n",
              " 'полицейским': 'полицейский',\n",
              " 'пор': 'пора',\n",
              " 'порвалась': 'порваться',\n",
              " 'после': 'после',\n",
              " 'последние': 'последний',\n",
              " 'последний': 'последний',\n",
              " 'потому': 'потому',\n",
              " 'похоже': 'похоже',\n",
              " 'почти': 'почти',\n",
              " 'прах': 'прах',\n",
              " 'пределе': 'предел',\n",
              " 'прежде': 'прежде',\n",
              " 'прикончил': 'прикончить',\n",
              " 'прошло': 'пройти',\n",
              " 'пытались': 'пытаться',\n",
              " 'раз': 'раз',\n",
              " 'раздражать': 'раздражать',\n",
              " 'родился': 'родиться',\n",
              " 'с': 'с',\n",
              " 'сбросил': 'сбросить',\n",
              " 'свалится': 'свалиться',\n",
              " 'своими': 'свой',\n",
              " 'сдохнуть': 'сдохнуть',\n",
              " 'себя': 'себя',\n",
              " 'сегодня': 'сегодня',\n",
              " 'семье': 'семья',\n",
              " 'сих': 'сей',\n",
              " 'следа': 'след',\n",
              " 'слюной': 'слюна',\n",
              " 'сомневался': 'сомневаться',\n",
              " 'состоянии': 'состояние',\n",
              " 'спал': 'спать',\n",
              " 'способ': 'способ',\n",
              " 'стянуть': 'стянуть',\n",
              " 'так': 'так',\n",
              " 'теперь': 'теперь',\n",
              " 'тетки': 'тетка',\n",
              " 'тех': 'тот',\n",
              " 'то': 'тот',\n",
              " 'тогда': 'тогда',\n",
              " 'того': 'тот',\n",
              " 'тоже': 'тоже',\n",
              " 'только': 'только',\n",
              " 'торгового': 'торговый',\n",
              " 'точно': 'точно',\n",
              " 'три': 'три',\n",
              " 'трудно': 'трудный',\n",
              " 'у': 'у',\n",
              " 'убивал': 'убивать',\n",
              " 'убить': 'убить',\n",
              " 'удавалось': 'удаваться',\n",
              " 'уж': 'уж',\n",
              " 'уже': 'уже',\n",
              " 'укусить': 'укусить',\n",
              " 'умереть': 'умереть',\n",
              " 'умирают': 'умирать',\n",
              " 'утром': 'утро',\n",
              " 'училищ': 'училище',\n",
              " 'февраля': 'февраль',\n",
              " 'холма': 'холм',\n",
              " 'хоть': 'хоть',\n",
              " 'хотя': 'хотя',\n",
              " 'часа': 'час',\n",
              " 'чем': 'чем',\n",
              " 'черствый': 'черствый',\n",
              " 'что': 'что',\n",
              " 'шарами': 'шар',\n",
              " 'эти': 'этот',\n",
              " 'этом': 'это',\n",
              " 'января': 'январь',\n",
              " 'ящик': 'ящик',\n",
              " '–': '–',\n",
              " '…': '…'}"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc2 = n_lemmatize(text2)\n",
        "{_.text: _.lemma for _ in n_doc2.tokens}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxBRWEXETPh3",
        "outputId": "a4a49124-8f62-4acd-d2ac-9b7c7ad11264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{',': ',',\n",
              " '.': '.',\n",
              " '«': '«',\n",
              " '»': '»',\n",
              " 'Ба́умана': 'ба́уман',\n",
              " 'Баумана': 'бауман',\n",
              " 'МГТУ': 'мгту',\n",
              " 'Моско́вское': 'моско́вский',\n",
              " 'Н': 'н',\n",
              " 'Николая': 'николай',\n",
              " 'Предыдущее': 'предыдущий',\n",
              " 'Э': 'э',\n",
              " 'Эрнестовича': 'эрнестович',\n",
              " 'было': 'быть',\n",
              " 'в': 'в',\n",
              " 'вы́сшее': 'вы́сшее',\n",
              " 'ему': 'он',\n",
              " 'им': 'он',\n",
              " 'исследовательский': 'исследовательский',\n",
              " 'название': 'название',\n",
              " 'национальный': 'национальный',\n",
              " 'присвоено': 'присвоить',\n",
              " 'революционера': 'революционер',\n",
              " 'российский': 'российский',\n",
              " 'техни́ческое': 'техни́ческий',\n",
              " 'университет': 'университет',\n",
              " 'университета': 'университет',\n",
              " 'учи́лище': 'учи́лище',\n",
              " 'честь': 'честь',\n",
              " '—': '—'}"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выделение (распознавание) именованных сущностей, named-entity recognition (NER)"
      ],
      "metadata": {
        "id": "xzt6FOTE6YhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "MSX-GdtIvgJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in spacy_test.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "elJZ4cNi6jSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c402b35-977f-4a8d-bfe4-dfa3f1a7968f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "несмотря на далёкий путь PERSON\n",
            "чтобы провести этот праздник дома PERSON\n",
            "со своими PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"ORDINAL\"))"
      ],
      "metadata": {
        "id": "nzDwTR9u6lVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba0e748-75fc-44f3-d3d3-843e3d063533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"first\", \"second\", etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"PRODUCT\"))"
      ],
      "metadata": {
        "id": "6m_kq2DR6n7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c5c630-1c14-497a-ae02-c4ec97c8fefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objects, vehicles, foods, etc. (not services)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"LOC\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcUfuAtywA2D",
        "outputId": "00a4f8cf-a0f1-4cdd-e271-c94ad6de47a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-GPE locations, mountain ranges, bodies of water\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"PER\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuhDw6-ZwCrq",
        "outputId": "c8e50d30-6d7e-4252-9a2a-4804fff5fe15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named person or family.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(spacy_test, style='ent', jupyter=True)"
      ],
      "metadata": {
        "id": "BUmx3tiP6qWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "488d3280-60ba-4c79-8a39-3a562fa157d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Праздник весны является самым любимым праздником китайцев .Накануне его китайцы ,которые　рабатают или занимаются в других местах, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    несмотря на далёкий путь\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", всегда спешат к родным очагам, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    чтобы провести этот праздник дома\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    со своими\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " близкими.</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "TtXrGtU1wNJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from slovnet import NER\n",
        "from ipymarkup import show_span_ascii_markup as show_markup"
      ],
      "metadata": {
        "id": "k71MCf2uTTQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner = NER.load('slovnet_ner_news_v1.tar')"
      ],
      "metadata": {
        "id": "IBmhEnBVTUFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_res = ner.navec(navec)"
      ],
      "metadata": {
        "id": "1Xpqt132Tvc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markup_ner = ner(text2)\n",
        "markup_ner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAg6lE7NTxUQ",
        "outputId": "dc7e9c19-1169-4422-fa27-8e7fa2ef971d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SpanMarkup(\n",
              "    text='МГТУ им. Н. Э. Ба́умана  — российский национальный исследовательский университет, Предыдущее название университета «Моско́вское вы́сшее техни́ческое учи́лище им. Н. Э. Ба́умана» было присвоено ему в честь революционера Николая Эрнестовича Баумана, ',\n",
              "    spans=[Span(\n",
              "         start=0,\n",
              "         stop=23,\n",
              "         type='ORG'\n",
              "     ), Span(\n",
              "         start=116,\n",
              "         stop=176,\n",
              "         type='ORG'\n",
              "     ), Span(\n",
              "         start=219,\n",
              "         stop=246,\n",
              "         type='PER'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_markup(markup_ner.text, markup_ner.spans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyy5je16Tx8b",
        "outputId": "ffca95e6-0971-48b0-bce0-8a06c3c272e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "МГТУ им. Н. Э. Ба́умана  — российский национальный исследовательский \n",
            "ORG────────────────────                                              \n",
            "университет, Предыдущее название университета «Моско́вское вы́сшее \n",
            "                                               ORG─────────────────\n",
            "техни́ческое учи́лище им. Н. Э. Ба́умана» было присвоено ему в честь \n",
            "────────────────────────────────────────                             \n",
            "революционера Николая Эрнестовича Баумана, \n",
            "              PER────────────────────────  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разбор предложения"
      ],
      "metadata": {
        "id": "l0-NMKkH6wt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "6GLpWaZvwesW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "EQjYJFSswnBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(spacy_test, style='dep', jupyter=True)"
      ],
      "metadata": {
        "id": "hoD3K9j-64z5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "0385ac4b-cddb-4376-c6ec-9e04eb065047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"aa5779ff0791416c8b331bfc240c31dc-0\" class=\"displacy\" width=\"6175\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Праздник</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">весны</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">является</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">самым</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">любимым</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">праздником</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">китайцев</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">.Накануне</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PUNCT</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">его</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">китайцы ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">которые</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">　</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">рабатают</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">или</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">занимаются</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">в</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">других</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">местах,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">несмотря</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">на</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">далёкий</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">путь,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">всегда</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">спешат</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">к</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">родным</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4600\">очагам,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4600\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4775\">чтобы</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4775\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4950\">провести</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4950\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5125\">этот</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5125\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5300\">праздник</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5300\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5475\">дома,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5475\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5650\">со</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5650\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"5825\">своими</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"5825\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"6000\">близкими.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"6000\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-0\" stroke-width=\"2px\" d=\"M70,527.0 C70,439.5 200.0,439.5 200.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,529.0 L62,517.0 78,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-1\" stroke-width=\"2px\" d=\"M245,527.0 C245,89.5 1095.0,89.5 1095.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,529.0 L237,517.0 253,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-2\" stroke-width=\"2px\" d=\"M420,527.0 C420,439.5 550.0,439.5 550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,529.0 L412,517.0 428,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-3\" stroke-width=\"2px\" d=\"M595,527.0 C595,439.5 725.0,439.5 725.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,529.0 L587,517.0 603,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-4\" stroke-width=\"2px\" d=\"M770,527.0 C770,352.0 1080.0,352.0 1080.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,529.0 L762,517.0 778,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-5\" stroke-width=\"2px\" d=\"M945,527.0 C945,439.5 1075.0,439.5 1075.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,529.0 L937,517.0 953,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-6\" stroke-width=\"2px\" d=\"M1120,527.0 C1120,439.5 1250.0,439.5 1250.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1250.0,529.0 L1258.0,517.0 1242.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-7\" stroke-width=\"2px\" d=\"M1470,527.0 C1470,439.5 1600.0,439.5 1600.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,529.0 L1462,517.0 1478,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-8\" stroke-width=\"2px\" d=\"M1645,527.0 C1645,439.5 1775.0,439.5 1775.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,529.0 L1637,517.0 1653,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-9\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,439.5 1950.0,439.5 1950.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1950.0,529.0 L1958.0,517.0 1942.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-10\" stroke-width=\"2px\" d=\"M2170,527.0 C2170,439.5 2300.0,439.5 2300.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,529.0 L2162,517.0 2178,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-11\" stroke-width=\"2px\" d=\"M1820,527.0 C1820,264.5 2310.0,264.5 2310.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2310.0,529.0 L2318.0,517.0 2302.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-12\" stroke-width=\"2px\" d=\"M2520,527.0 C2520,264.5 3010.0,264.5 3010.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2520,529.0 L2512,517.0 2528,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-13\" stroke-width=\"2px\" d=\"M2695,527.0 C2695,352.0 3005.0,352.0 3005.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2695,529.0 L2687,517.0 2703,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-14\" stroke-width=\"2px\" d=\"M2870,527.0 C2870,439.5 3000.0,439.5 3000.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2870,529.0 L2862,517.0 2878,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-15\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,177.0 3015.0,177.0 3015.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3015.0,529.0 L3023.0,517.0 3007.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-16\" stroke-width=\"2px\" d=\"M3220,527.0 C3220,439.5 3350.0,439.5 3350.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3220,529.0 L3212,517.0 3228,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-17\" stroke-width=\"2px\" d=\"M3395,527.0 C3395,352.0 3705.0,352.0 3705.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3395,529.0 L3387,517.0 3403,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-18\" stroke-width=\"2px\" d=\"M3570,527.0 C3570,439.5 3700.0,439.5 3700.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3570,529.0 L3562,517.0 3578,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-19\" stroke-width=\"2px\" d=\"M3045,527.0 C3045,177.0 3715.0,177.0 3715.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3715.0,529.0 L3723.0,517.0 3707.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-20\" stroke-width=\"2px\" d=\"M3920,527.0 C3920,177.0 4590.0,177.0 4590.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3920,529.0 L3912,517.0 3928,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-21\" stroke-width=\"2px\" d=\"M4095,527.0 C4095,264.5 4585.0,264.5 4585.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4095,529.0 L4087,517.0 4103,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-22\" stroke-width=\"2px\" d=\"M4270,527.0 C4270,352.0 4580.0,352.0 4580.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4270,529.0 L4262,517.0 4278,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-23\" stroke-width=\"2px\" d=\"M4445,527.0 C4445,439.5 4575.0,439.5 4575.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4445,529.0 L4437,517.0 4453,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-24\" stroke-width=\"2px\" d=\"M3745,527.0 C3745,89.5 4595.0,89.5 4595.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4595.0,529.0 L4603.0,517.0 4587.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-25\" stroke-width=\"2px\" d=\"M4795,527.0 C4795,439.5 4925.0,439.5 4925.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-25\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4795,529.0 L4787,517.0 4803,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-26\" stroke-width=\"2px\" d=\"M4970,527.0 C4970,439.5 5100.0,439.5 5100.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-26\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M4970,529.0 L4962,517.0 4978,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-27\" stroke-width=\"2px\" d=\"M2345,527.0 C2345,2.0 5125.0,2.0 5125.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-27\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5125.0,529.0 L5133.0,517.0 5117.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-28\" stroke-width=\"2px\" d=\"M5320,527.0 C5320,439.5 5450.0,439.5 5450.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-28\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5320,529.0 L5312,517.0 5328,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-29\" stroke-width=\"2px\" d=\"M5145,527.0 C5145,352.0 5455.0,352.0 5455.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-29\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5455.0,529.0 L5463.0,517.0 5447.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-30\" stroke-width=\"2px\" d=\"M5670,527.0 C5670,352.0 5980.0,352.0 5980.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-30\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5670,529.0 L5662,517.0 5678,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-31\" stroke-width=\"2px\" d=\"M5845,527.0 C5845,439.5 5975.0,439.5 5975.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-31\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5845,529.0 L5837,517.0 5853,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-aa5779ff0791416c8b331bfc240c31dc-0-32\" stroke-width=\"2px\" d=\"M5495,527.0 C5495,264.5 5985.0,264.5 5985.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-aa5779ff0791416c8b331bfc240c31dc-0-32\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M5985.0,529.0 L5993.0,517.0 5977.0,517.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"NOUN\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2lRZT0dw2I4",
        "outputId": "28ff7c90-39de-4824-fad4-5b616e08b85e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spacy.explain(\"amod\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSU_3-oYw2q_",
        "outputId": "051180b0-1731-463d-fc62-794d3d4364e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjectival modifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natasha**"
      ],
      "metadata": {
        "id": "Dugy2uyDwgjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from natasha import NewsSyntaxParser"
      ],
      "metadata": {
        "id": "FNu8VYImUBDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = NewsEmbedding()\n",
        "syntax_parser = NewsSyntaxParser(emb)"
      ],
      "metadata": {
        "id": "qXalehZMUB0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[0].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmYR0kU3UDj1",
        "outputId": "b8a6ea11-3258-423d-f478-29c787e24499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  ┌──► Дмитрий     nsubj\n",
            "                  │ ┌─ Иванович    \n",
            "                  │ └► Менделеев   flat:name\n",
            "┌─┌───────┌─┌─┌───└─┌─ родился     \n",
            "│ │ ┌─────│ │ │   ┌─└► 27          obl\n",
            "│ │ │     │ │ │   └──► января      flat\n",
            "│ │ │     │ │ │     ┌► (           punct\n",
            "│ │ │ ┌──►│ │ │ ┌─┌─└─ 8           parataxis\n",
            "│ │ │ │   │ │ │ │ └──► февраля     flat\n",
            "│ │ │ │   │ │ │ └────► )           punct\n",
            "│ │ │ │   │ │ │     ┌► 1834        amod\n",
            "│ │ │ │   │ │ └────►└─ года        obl\n",
            "│ │ │ │   │ │       ┌► в           case\n",
            "│ │ │ │   │ └──────►└─ Тобольске   obl\n",
            "│ │ │ │   │         ┌► в           case\n",
            "│ │ │ │   └──────►┌─└─ семье       obl\n",
            "│ │ │ │         ┌─└►┌─ Ивана       nmod\n",
            "│ │ │ │         │   └► Павловича   flat:name\n",
            "│ │ │ │         └────► Менделеева  flat:name\n",
            "│ │ │ │         ┌────► ,           punct\n",
            "│ │ │ │         │ ┌──► в           case\n",
            "│ │ │ │         │ │ ┌► то          det\n",
            "│ │ │ │         │ └─└─ время       obl\n",
            "│ │ │ │   ┌────►└─└─┌─ занимавшего acl\n",
            "│ │ │ │   │       ┌─└► должность   obj\n",
            "│ │ │ │   │ ┌───┌─└──► директора   nmod\n",
            "│ │ │ │   │ │   │   ┌► Тобольской  amod\n",
            "│ │ │ │   │ │ ┌─└──►└─ гимназии    nmod\n",
            "│ │ │ │   │ │ │     ┌► и           cc\n",
            "│ │ │ │   │ │ └────►└─ училищ      conj\n",
            "│ │ │ │   │ │       ┌► Тобольского amod\n",
            "│ │ │ │   │ └──────►└─ округа      nmod\n",
            "│ │ │ │ ┌►│            ,           punct\n",
            "│ │ │ │ │ │         ┌► и           cc\n",
            "│ │ └►└─│ └───┌─┌─┌─└─ Марии       conj\n",
            "│ │     │     │ │ └──► Дмитриевны  flat:name\n",
            "│ │     │     │ └────► Менделеевой flat:name\n",
            "│ │     │     │     ┌► (           punct\n",
            "│ │     │     └──►┌─└─ Корнильевой appos\n",
            "│ │     │         └──► )           punct\n",
            "│ └────►│              .           punct\n",
            "│       │         ┌──► Эти         det\n",
            "│       │         │ ┌► змееволосые amod\n",
            "│       │       ┌►└─└─ дамочки     nsubj\n",
            "│       │       │   ┌► уже         advmod\n",
            "│       └───────└─┌─└─ начали      \n",
            "│                 └►┌─ раздражать  xcomp\n",
            "│                   └► Перси       obj\n",
            "└────────────────────► .           punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[1].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDGZC_59UJA6",
        "outputId": "eaba5e6c-1d4e-44c2-86f1-a13a5f9440eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ┌► Они          nsubj\n",
            "┌─────┌─┌─└─ должны       \n",
            "│     │ └──► были         cop\n",
            "│ ┌─┌─└────► умереть      xcomp\n",
            "│ │ │   ┌──► еще          advmod\n",
            "│ │ │   │ ┌► три          nummod:gov\n",
            "│ │ └──►└─└─ дня          obl\n",
            "│ │     └──► назад        advmod\n",
            "│ │   ┌────► ,            punct\n",
            "│ │   │ ┌──► когда        mark\n",
            "│ │   │ │ ┌► он           nsubj\n",
            "│ └►┌─└─└─└─ сбросил      advcl\n",
            "│   │ │   ┌► на           case\n",
            "│   │ └──►└─ них          obl\n",
            "│   └──►┌─── ящик         obj\n",
            "│       │ ┌► с            case\n",
            "│     ┌─└►└─ шарами       nmod\n",
            "│     │   ┌► для          case\n",
            "│ ┌─┌─└──►└─ боулинга     nmod\n",
            "│ │ │   ┌──► в            case\n",
            "│ │ │   │ ┌► «            punct\n",
            "│ │ └──►└─└─ Баргин-Марте nmod\n",
            "│ │     └──► »            punct\n",
            "│ │       ┌► в            case\n",
            "│ └──────►└─ Напе         nmod\n",
            "└──────────► .            punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc.parse_syntax(syntax_parser)\n",
        "n_doc.sents[2].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lNMWNw5UJfZ",
        "outputId": "6e12866f-987a-4b40-d9f1-3f9fe90d5cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ┌► Они         nsubj\n",
            "┌───┌───┌─┌─└─ должны      \n",
            "│   │   │ └──► были        cop\n",
            "│ ┌─│   └──►┌─ отдать      xcomp\n",
            "│ │ │       └► концы       obj\n",
            "│ │ │       ┌► два         nummod:gov\n",
            "│ │ │ ┌──►┌─└─ дня         obl\n",
            "│ │ │ │   └──► назад       advmod\n",
            "│ │ │ │   ┌──► ,           punct\n",
            "│ │ │ │   │ ┌► после       case\n",
            "│ │ └►│ ┌─└─└─ того        obl\n",
            "│ │   │ │ ┌──► как         mark\n",
            "│ │   │ │ │ ┌► он          nsubj\n",
            "│ │   └─└►└─└─ переехал    acl\n",
            "│ │       ┌──► их          det\n",
            "│ │       │ ┌► полицейским amod\n",
            "│ └────►┌─└─└─ автомобилем iobj\n",
            "│       │   ┌► в           case\n",
            "│       └──►└─ Мартинесе   nmod\n",
            "└────────────► .           punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_doc2.parse_syntax(syntax_parser)\n",
        "n_doc2.sents[0].syntax.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW_vyRu4UQue",
        "outputId": "92b24096-5249-48de-8f9e-f21052e7ffe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                ┌────────► МГТУ              acl\n",
            "                │     ┌─── им                \n",
            "                │     │ ┌► .                 punct\n",
            "  ┌───┌─────┌──►│     │ └─ Н                 nmod\n",
            "  │ ┌►│     │   │     │    .                 punct\n",
            "  │ │ │   ┌►│   │     │    Э                 flat:name\n",
            "  │ │ │   │ │   │     └──► .                 punct\n",
            "┌►│ │ │   │ │   │          Ба́умана          flat:name\n",
            "│ │ │ │   │ │   │ ┌──────► —                 punct\n",
            "│ │ │ │   │ │   │ │ ┌────► российский        amod\n",
            "│ │ │ │   │ │   │ │ │ ┌──► национальный      amod\n",
            "│ │ │ │   │ │   │ │ │ │ ┌► исследовательский amod\n",
            "│ │ │ │ ┌►│ │   └─│ └─└─└─ университет       nsubj:pass\n",
            "│ │ │ │ │ │ │   │ │   ┌──► ,                 punct\n",
            "│ │ │ │ │ │ │   │ │   │ ┌► Предыдущее        amod\n",
            "│ │ │ │ │ │ │ ┌►│ └───└─└─ название          nsubj:pass\n",
            "│ │ │ │ │ │ │ │ │     └──► университета      nmod\n",
            "│ │ │ │ │ │ │ │ │       ┌► «                 punct\n",
            "│ │ │ │ │ │ │ │ │   ┌──►└─ Моско́вское       amod\n",
            "│ │ │ │ │ │ │ │ │   │   ┌► вы́сшее           amod\n",
            "│ │ │ │ │ │ │ │ │   │ ┌►└─ техни́ческое      amod\n",
            "│ │ │ │ │ │ │ │ └──►└─│    учи́лище          amod\n",
            "│ │ │ │ │ │ └─│ ┌►┌───└─┌─ им                iobj\n",
            "│ │ │ └►│ │   │ │ │     │  .                 punct\n",
            "│ │ └───│ └───│ │ │ ┌─┌─└► Н                 nmod\n",
            "│ │     │     │ │ │ │ │ └► .                 punct\n",
            "│ │     │     │ │ │ │ └──► Э                 flat:name\n",
            "│ └────►│     │ │ │ │      .                 punct\n",
            "│       │     │ │ │ └────► Ба́умана          flat:name\n",
            "│       │     │ │ └──────► »                 punct\n",
            "│       │     │ │       ┌► было              aux:pass\n",
            "│       └─────└─└─┌─┌─┌─└─ присвоено         \n",
            "│                 │ │ └──► ему               iobj\n",
            "│                 │ │   ┌► в                 case\n",
            "│                 │ └►┌─└─ честь             obl\n",
            "│                 │   └►┌─ революционера     nmod\n",
            "└─────────────────│ ┌─┌─└► Николая           appos\n",
            "                  │ │ └──► Эрнестовича       flat:name\n",
            "                  │ └────► Баумана           flat:name\n",
            "                  └──────► ,                 punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Решение задачи классификации текста"
      ],
      "metadata": {
        "id": "0s2nPDA667h3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключение библиотек\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "sns.set(style=\"ticks\")"
      ],
      "metadata": {
        "id": "IsER1seMUV7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Способ 1. Векторизация текста на основе модели \"мешка слов\""
      ],
      "metadata": {
        "id": "nmJGqBvV7GEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ],
      "metadata": {
        "id": "zKkabKZ7z1x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "iNoccxXdz7I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect = CountVectorizer()\n",
        "vocabVect.fit(data)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ],
      "metadata": {
        "id": "p4g8eaIq7JJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15fd1238-593a-4d96-ebe1-25731af6b07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество сформированных признаков - 33448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP9LOSVd0Hr6",
        "outputId": "9ef287c9-b35b-4110-d655-a9523043e2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nrmendel=22213\n",
            "unix=31462\n",
            "amherst=5287\n",
            "edu=12444\n",
            "nathaniel=21624\n",
            "mendell=20477\n",
            "subject=29220\n",
            "re=25369\n",
            "bike=6898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Использование класса CountVectorizer"
      ],
      "metadata": {
        "id": "-oehFFc_0Jxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = vocabVect.transform(data)\n",
        "test_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiDvLcMP0OdS",
        "outputId": "7f1df069-6654-4972-87bf-2cad8b61cb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2380x33448 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 335176 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_features.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46IRFoM0PD2",
        "outputId": "63fb8733-81f9-4dc4-f9e2-5539f4e1b656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [2, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFE1_bnw0QLn",
        "outputId": "22c14082-2135-4377-9431-4331a0e7081c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33448"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Непустые значения нулевой строки\n",
        "print([i for i in test_features.todense()[0].getA1() if i>0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4svP_Y90UUV",
        "outputId": "313297b1-fd94-4b4c-bfc3-ee77257d8a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabVect.get_feature_names()[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39bigzZS0WJh",
        "outputId": "7701215f-2820-44f2-d1b8-d6905e2b482d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " '000',\n",
              " '0000',\n",
              " '0000000004',\n",
              " '0000000005',\n",
              " '0000000667',\n",
              " '0000001200',\n",
              " '0001',\n",
              " '00014',\n",
              " '0002']"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Решение задачи анализа тональности текста на основе модели \"мешка слов\""
      ],
      "metadata": {
        "id": "XhsMJ-RI0bh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
        "    for v in vectorizers_list:\n",
        "        for c in classifiers_list:\n",
        "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
        "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
        "            print('Векторизация - {}'.format(v))\n",
        "            print('Модель для классификации - {}'.format(c))\n",
        "            print('Accuracy = {}'.format(score))\n",
        "            print('===========================')"
      ],
      "metadata": {
        "id": "dLvJ4qLP0fzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab)]\n",
        "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
        "VectorizeAndClassify(vectorizers_list, classifiers_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIwIT0GN0jXZ",
        "outputId": "f2b429fd-d4df-4b13-b354-4c985228009c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - LogisticRegression(C=3.0)\n",
            "Accuracy = 0.937813339432037\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - LinearSVC()\n",
            "Accuracy = 0.9453742497059174\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
            "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
            "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
            "                            '0005111312': 11, '0005111312na1em': 12,\n",
            "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
            "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
            "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
            "                            '001813': 24, '002': 25, '002222': 26,\n",
            "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
            "Модель для классификации - KNeighborsClassifier()\n",
            "Accuracy = 0.6655358653541747\n",
            "===========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
      ],
      "metadata": {
        "id": "ZdQHu4i80m1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups['data'], newsgroups['target'], test_size=0.5, random_state=1)"
      ],
      "metadata": {
        "id": "RCva3Dn00qmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "3OXeo6WY0tHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(CountVectorizer(), LinearSVC())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxBlSZf10rnO",
        "outputId": "8eadcfbb-5de9-4467-fae4-039343d13c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.9290322580645162\n",
            "1 \t 0.9675090252707581\n",
            "2 \t 0.9026845637583892\n",
            "3 \t 0.9245901639344263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Способ 2. Работа с векторными представлениями слов с использованием word2vec"
      ],
      "metadata": {
        "id": "KUTzDcml7SxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import word2vec"
      ],
      "metadata": {
        "id": "4iUhQZK87P_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zukmfaIYzQXU",
        "outputId": "446bb59f-113d-4a2f-be69-7ffece741dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "QEMPbEfg7Qgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46fc7689-8889-4590-eb84-960a6f53b560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/ruscorpora_mystem_cbow_300_2_2015 (1).bin.gz'"
      ],
      "metadata": {
        "id": "P8_lVGnGzW2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
      ],
      "metadata": {
        "id": "CCquN4PnzYiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['холод_S', 'мороз_S', 'береза_S', 'сосна_S']"
      ],
      "metadata": {
        "id": "Ob2o7nqvza8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    if word in model:\n",
        "        print('\\nСЛОВО - {}'.format(word))\n",
        "        print('5 ближайших соседей слова:')\n",
        "        for word, sim in model.most_similar(positive=[word], topn=5):\n",
        "            print('{} => {}'.format(word, sim))\n",
        "    else:\n",
        "        print('Слово \"{}\" не найдено в модели'.format(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH1vkqqYLKSz",
        "outputId": "aaabd2b4-ff68-4c6a-b2e6-ae6c93800bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "СЛОВО - холод_S\n",
            "5 ближайших соседей слова:\n",
            "стужа_S => 0.7676383852958679\n",
            "сырость_S => 0.6338975429534912\n",
            "жара_S => 0.6089427471160889\n",
            "мороз_S => 0.5890367031097412\n",
            "озноб_S => 0.5776054859161377\n",
            "\n",
            "СЛОВО - мороз_S\n",
            "5 ближайших соседей слова:\n",
            "стужа_S => 0.6425479650497437\n",
            "морозец_S => 0.5947279930114746\n",
            "холод_S => 0.5890367031097412\n",
            "жара_S => 0.5522176623344421\n",
            "снегопад_S => 0.5083199143409729\n",
            "\n",
            "СЛОВО - береза_S\n",
            "5 ближайших соседей слова:\n",
            "сосна_S => 0.7943247556686401\n",
            "тополь_S => 0.7562226057052612\n",
            "дуб_S => 0.7440178394317627\n",
            "дерево_S => 0.7373415231704712\n",
            "клен_S => 0.7105200290679932\n",
            "\n",
            "СЛОВО - сосна_S\n",
            "5 ближайших соседей слова:\n",
            "береза_S => 0.7943247556686401\n",
            "дерево_S => 0.7581434845924377\n",
            "лиственница_S => 0.747814953327179\n",
            "дуб_S => 0.7412480711936951\n",
            "ель_S => 0.7363824248313904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Находим близость между словами и строим аналогии"
      ],
      "metadata": {
        "id": "7CAGq-izLPgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity('сосна_S', 'береза_S'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJBfNzIILRcP",
        "outputId": "9920319d-4af9-4cf1-9106-fd2f1bbea9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7943247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.most_similar(positive=['холод_S', 'стужа_S'], negative=['мороз_S']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boueOfMzLXZL",
        "outputId": "67475eab-f9d1-406b-c39a-45cccc2d63ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('сырость_S', 0.5040211081504822), ('стылость_S', 0.46336129307746887), ('голод_S', 0.4604816436767578), ('зной_S', 0.45904627442359924), ('скука_S', 0.4489358067512512), ('жара_S', 0.44645121693611145), ('усталость_S', 0.4218570291996002), ('озноб_S', 0.41469818353652954), ('духота_S', 0.4099087715148926), ('неуют_S', 0.40298789739608765)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучим word2vec на наборе данных \"fetch_20newsgroups\""
      ],
      "metadata": {
        "id": "OqWfo1fVLaA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXuRnboRLchG",
        "outputId": "f2f70cfd-a11a-46e5-d888-cba73d79e8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
        "data = newsgroups['data']"
      ],
      "metadata": {
        "id": "aMCXWxcsLe3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим корпус\n",
        "corpus = []\n",
        "stop_words = stopwords.words('english')\n",
        "tok = WordPunctTokenizer()\n",
        "for line in newsgroups['data']:\n",
        "    line1 = line.strip().lower()\n",
        "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
        "    text_tok = tok.tokenize(line1)\n",
        "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
        "    corpus.append(text_tok1)"
      ],
      "metadata": {
        "id": "SISZtThA7VTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:5]"
      ],
      "metadata": {
        "id": "8VBjkNGC7Xzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa9a49e-2fc3-4957-e18e-892218597c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['nrmendel',\n",
              "  'unix',\n",
              "  'amherst',\n",
              "  'edu',\n",
              "  'nathaniel',\n",
              "  'mendell',\n",
              "  'subject',\n",
              "  'bike',\n",
              "  'advice',\n",
              "  'organization',\n",
              "  'amherst',\n",
              "  'college',\n",
              "  'x',\n",
              "  'newsreader',\n",
              "  'tin',\n",
              "  'version',\n",
              "  'pl',\n",
              "  'lines',\n",
              "  'ummm',\n",
              "  'bikes',\n",
              "  'kx',\n",
              "  'suggest',\n",
              "  'look',\n",
              "  'zx',\n",
              "  'since',\n",
              "  'horsepower',\n",
              "  'whereas',\n",
              "  'might',\n",
              "  'bit',\n",
              "  'much',\n",
              "  'sincerely',\n",
              "  'nathaniel',\n",
              "  'zx',\n",
              "  'dod',\n",
              "  'ama'],\n",
              " ['grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'subject',\n",
              "  'krillean',\n",
              "  'photography',\n",
              "  'reply',\n",
              "  'grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'organization',\n",
              "  'rosemount',\n",
              "  'inc',\n",
              "  'lines',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'aquarius',\n",
              "  'stgprao',\n",
              "  'st',\n",
              "  'unocal',\n",
              "  'com',\n",
              "  'richard',\n",
              "  'ottolini',\n",
              "  'writes',\n",
              "  'living',\n",
              "  'things',\n",
              "  'maintain',\n",
              "  'small',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'enhance',\n",
              "  'certain',\n",
              "  'chemical',\n",
              "  'reactions',\n",
              "  'promote',\n",
              "  'communication',\n",
              "  'states',\n",
              "  'cell',\n",
              "  'communicate',\n",
              "  'cells',\n",
              "  'nervous',\n",
              "  'system',\n",
              "  'specialized',\n",
              "  'example',\n",
              "  'perhaps',\n",
              "  'uses',\n",
              "  'true',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'change',\n",
              "  'location',\n",
              "  'time',\n",
              "  'large',\n",
              "  'organism',\n",
              "  'also',\n",
              "  'true',\n",
              "  'special',\n",
              "  'photographic',\n",
              "  'techniques',\n",
              "  'applying',\n",
              "  'external',\n",
              "  'fields',\n",
              "  'kirillian',\n",
              "  'photography',\n",
              "  'interact',\n",
              "  'fields',\n",
              "  'resistances',\n",
              "  'caused',\n",
              "  'fields',\n",
              "  'make',\n",
              "  'interesting',\n",
              "  'pictures',\n",
              "  'really',\n",
              "  'kirlian',\n",
              "  'photography',\n",
              "  'taking',\n",
              "  'pictures',\n",
              "  'corona',\n",
              "  'discharge',\n",
              "  'objects',\n",
              "  'animate',\n",
              "  'inanimate',\n",
              "  'fields',\n",
              "  'applied',\n",
              "  'objects',\n",
              "  'millions',\n",
              "  'times',\n",
              "  'larger',\n",
              "  'biologically',\n",
              "  'created',\n",
              "  'fields',\n",
              "  'want',\n",
              "  'record',\n",
              "  'biologically',\n",
              "  'created',\n",
              "  'electric',\n",
              "  'fields',\n",
              "  'got',\n",
              "  'use',\n",
              "  'low',\n",
              "  'noise',\n",
              "  'high',\n",
              "  'gain',\n",
              "  'sensors',\n",
              "  'typical',\n",
              "  'eegs',\n",
              "  'ekgs',\n",
              "  'kirlian',\n",
              "  'photography',\n",
              "  'phun',\n",
              "  'physics',\n",
              "  'type',\n",
              "  'stuff',\n",
              "  'right',\n",
              "  'soaking',\n",
              "  'chunks',\n",
              "  'extra',\n",
              "  'fine',\n",
              "  'steel',\n",
              "  'wool',\n",
              "  'liquid',\n",
              "  'oxygen',\n",
              "  'hitting',\n",
              "  'hammer',\n",
              "  'like',\n",
              "  'kirlean',\n",
              "  'setup',\n",
              "  'fun',\n",
              "  'possibly',\n",
              "  'dangerous',\n",
              "  'perhaps',\n",
              "  'pictures',\n",
              "  'diagonistic',\n",
              "  'disease',\n",
              "  'problems',\n",
              "  'organisms',\n",
              "  'better',\n",
              "  'understood',\n",
              "  'perhaps',\n",
              "  'probably',\n",
              "  'grant',\n",
              "  'edwards',\n",
              "  'yow',\n",
              "  'vote',\n",
              "  'rosemount',\n",
              "  'inc',\n",
              "  'well',\n",
              "  'tapered',\n",
              "  'half',\n",
              "  'cocked',\n",
              "  'ill',\n",
              "  'conceived',\n",
              "  'grante',\n",
              "  'aquarius',\n",
              "  'rosemount',\n",
              "  'com',\n",
              "  'tax',\n",
              "  'deferred'],\n",
              " ['liny',\n",
              "  'sun',\n",
              "  'scri',\n",
              "  'fsu',\n",
              "  'edu',\n",
              "  'nemo',\n",
              "  'subject',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'myopia',\n",
              "  'reply',\n",
              "  'lin',\n",
              "  'ray',\n",
              "  'met',\n",
              "  'fsu',\n",
              "  'edu',\n",
              "  'distribution',\n",
              "  'na',\n",
              "  'organization',\n",
              "  'scri',\n",
              "  'florida',\n",
              "  'state',\n",
              "  'university',\n",
              "  'lines',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'work',\n",
              "  'first',\n",
              "  'heard',\n",
              "  'newsgroup',\n",
              "  'several',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'got',\n",
              "  'hold',\n",
              "  'book',\n",
              "  'improve',\n",
              "  'sight',\n",
              "  'simple',\n",
              "  'daily',\n",
              "  'drills',\n",
              "  'relaxation',\n",
              "  'margaret',\n",
              "  'corbett',\n",
              "  'authorized',\n",
              "  'instructor',\n",
              "  'bates',\n",
              "  'method',\n",
              "  'published',\n",
              "  'talks',\n",
              "  'vision',\n",
              "  'improvement',\n",
              "  'relaxation',\n",
              "  'exercise',\n",
              "  'study',\n",
              "  'whether',\n",
              "  'method',\n",
              "  'actually',\n",
              "  'works',\n",
              "  'works',\n",
              "  'actually',\n",
              "  'shortening',\n",
              "  'previously',\n",
              "  'elongated',\n",
              "  'eyeball',\n",
              "  'increasing',\n",
              "  'lens',\n",
              "  'ability',\n",
              "  'flatten',\n",
              "  'order',\n",
              "  'compensate',\n",
              "  'long',\n",
              "  'eyeball',\n",
              "  'since',\n",
              "  'myopia',\n",
              "  'result',\n",
              "  'eyeball',\n",
              "  'elongation',\n",
              "  'seems',\n",
              "  'logical',\n",
              "  'approach',\n",
              "  'correction',\n",
              "  'find',\n",
              "  'way',\n",
              "  'reverse',\n",
              "  'process',\n",
              "  'e',\n",
              "  'shorten',\n",
              "  'somehow',\n",
              "  'preferably',\n",
              "  'non',\n",
              "  'surgically',\n",
              "  'recent',\n",
              "  'studies',\n",
              "  'find',\n",
              "  'know',\n",
              "  'rk',\n",
              "  'works',\n",
              "  'changing',\n",
              "  'curvature',\n",
              "  'cornea',\n",
              "  'compensate',\n",
              "  'shape',\n",
              "  'eyeball',\n",
              "  'way',\n",
              "  'train',\n",
              "  'muscles',\n",
              "  'shorten',\n",
              "  'eyeball',\n",
              "  'back',\n",
              "  'correct',\n",
              "  'length',\n",
              "  'would',\n",
              "  'even',\n",
              "  'better',\n",
              "  'bates',\n",
              "  'idea',\n",
              "  'right',\n",
              "  'thanks',\n",
              "  'information'],\n",
              " ['mcovingt',\n",
              "  'aisun',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'michael',\n",
              "  'covington',\n",
              "  'subject',\n",
              "  'buy',\n",
              "  'parts',\n",
              "  'time',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'aisun',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'organization',\n",
              "  'ai',\n",
              "  'programs',\n",
              "  'university',\n",
              "  'georgia',\n",
              "  'athens',\n",
              "  'lines',\n",
              "  'pricing',\n",
              "  'parts',\n",
              "  'reminds',\n",
              "  'something',\n",
              "  'chemist',\n",
              "  'said',\n",
              "  'gram',\n",
              "  'dye',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'comes',\n",
              "  'liter',\n",
              "  'jar',\n",
              "  'also',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'want',\n",
              "  'whole',\n",
              "  'barrel',\n",
              "  'also',\n",
              "  'costs',\n",
              "  'dollar',\n",
              "  'e',\n",
              "  'charge',\n",
              "  'almost',\n",
              "  'exclusively',\n",
              "  'packaging',\n",
              "  'delivering',\n",
              "  'chemical',\n",
              "  'particular',\n",
              "  'case',\n",
              "  'byproduct',\n",
              "  'cost',\n",
              "  'almost',\n",
              "  'nothing',\n",
              "  'intrinsically',\n",
              "  'michael',\n",
              "  'covington',\n",
              "  'associate',\n",
              "  'research',\n",
              "  'scientist',\n",
              "  'artificial',\n",
              "  'intelligence',\n",
              "  'programs',\n",
              "  'mcovingt',\n",
              "  'ai',\n",
              "  'uga',\n",
              "  'edu',\n",
              "  'university',\n",
              "  'georgia',\n",
              "  'phone',\n",
              "  'athens',\n",
              "  'georgia',\n",
              "  'u',\n",
              "  'amateur',\n",
              "  'radio',\n",
              "  'n',\n",
              "  'tmi'],\n",
              " ['tammy',\n",
              "  'vandenboom',\n",
              "  'launchpad',\n",
              "  'unc',\n",
              "  'edu',\n",
              "  'tammy',\n",
              "  'vandenboom',\n",
              "  'subject',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'testicles',\n",
              "  'nntp',\n",
              "  'posting',\n",
              "  'host',\n",
              "  'lambada',\n",
              "  'oit',\n",
              "  'unc',\n",
              "  'edu',\n",
              "  'organization',\n",
              "  'university',\n",
              "  'north',\n",
              "  'carolina',\n",
              "  'extended',\n",
              "  'bulletin',\n",
              "  'board',\n",
              "  'service',\n",
              "  'distribution',\n",
              "  'na',\n",
              "  'lines',\n",
              "  'husband',\n",
              "  'woke',\n",
              "  'three',\n",
              "  'days',\n",
              "  'ago',\n",
              "  'small',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'spot',\n",
              "  'size',\n",
              "  'nickel',\n",
              "  'one',\n",
              "  'testicles',\n",
              "  'bottom',\n",
              "  'side',\n",
              "  'knots',\n",
              "  'lumps',\n",
              "  'little',\n",
              "  'sore',\n",
              "  'spot',\n",
              "  'says',\n",
              "  'reminds',\n",
              "  'bruise',\n",
              "  'feels',\n",
              "  'recollection',\n",
              "  'hitting',\n",
              "  'anything',\n",
              "  'like',\n",
              "  'would',\n",
              "  'cause',\n",
              "  'bruise',\n",
              "  'asssures',\n",
              "  'remember',\n",
              "  'something',\n",
              "  'like',\n",
              "  'clues',\n",
              "  'might',\n",
              "  'somewhat',\n",
              "  'hypochondriac',\n",
              "  'sp',\n",
              "  'sure',\n",
              "  'gonna',\n",
              "  'die',\n",
              "  'thanks',\n",
              "  'opinions',\n",
              "  'expressed',\n",
              "  'necessarily',\n",
              "  'university',\n",
              "  'north',\n",
              "  'carolina',\n",
              "  'chapel',\n",
              "  'hill',\n",
              "  'campus',\n",
              "  'office',\n",
              "  'information',\n",
              "  'technology',\n",
              "  'experimental',\n",
              "  'bulletin',\n",
              "  'board',\n",
              "  'service',\n",
              "  'internet',\n",
              "  'launchpad',\n",
              "  'unc',\n",
              "  'edu']]"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time model_dz = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
      ],
      "metadata": {
        "id": "g_gIEENn7Y5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c382bf-9ce7-4734-9751-0c959022a9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.62 s, sys: 36.3 ms, total: 5.66 s\n",
            "Wall time: 4.81 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверим, что модель обучилась\n",
        "print(model_dz.wv.most_similar(positive=['find'], topn=5))"
      ],
      "metadata": {
        "id": "wlix9xok7YwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b213b5e-175f-4d1d-ba26-ff2f43917511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('voltage', 0.9900681972503662), ('circuit', 0.9896678924560547), ('high', 0.9888499975204468), ('amp', 0.987079381942749), ('using', 0.985265851020813)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ix2AkQK-7hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Проверка качества работы модели word2vec"
      ],
      "metadata": {
        "id": "sv_8DZDUMC86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingVectorizer(object):\n",
        "    '''\n",
        "    Для текста усредним вектора входящих в него слов\n",
        "    '''\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.size = model.vector_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean(\n",
        "            [self.model[w] for w in words if w in self.model] \n",
        "            or [np.zeros(self.size)], axis=0)\n",
        "            for words in X])\n",
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "metadata": {
        "id": "bHykJZqQ7mcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучающая и тестовая выборки\n",
        "boundary = 1000\n",
        "X_train = corpus[:boundary] \n",
        "X_test = corpus[boundary:]\n",
        "y_train = newsgroups['target'][:boundary]\n",
        "y_test = newsgroups['target'][boundary:]"
      ],
      "metadata": {
        "id": "ahnn5qX57wpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "sentiment(EmbeddingVectorizer(model_dz.wv), LogisticRegression(C=5.0))"
      ],
      "metadata": {
        "id": "eQeebgTr7xVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1327211-bd17-4824-eb83-674240cfe144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.8005698005698005\n",
            "1 \t 0.9046153846153846\n",
            "2 \t 0.7391304347826086\n",
            "3 \t 0.7381615598885793\n",
            "CPU times: user 1.33 s, sys: 336 ms, total: 1.67 s\n",
            "Wall time: 1.73 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты:  \n",
        "Модель CountVectorizer\n",
        "\n",
        "```\n",
        "Метка \t Accuracy\n",
        "0 \t 0.9290322580645162\n",
        "1 \t 0.9675090252707581\n",
        "2 \t 0.9026845637583892\n",
        "3 \t 0.9245901639344263\n",
        "```\n",
        "Модель word2vec\n",
        "\n",
        "```\n",
        "Метка \t Accuracy\n",
        "0 \t 0.8233618233618234\n",
        "1 \t 0.9015384615384615\n",
        "2 \t 0.736231884057971\n",
        "3 \t 0.7214484679665738\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a4LqmUdaQdeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы\n",
        "Как видно из результатов проверки качества моделей, лучшее качество показал CountVectorizer.  \n",
        "Результаты, полученные с помощью word2vec не очень хоршие, скорее всего здесь нестандартность лексики ещё больше влияет на работу уже предобученной на более-менее формальных корпусах модели. Короткие неформальные сообщения скорее всего требуют немного других подходов."
      ],
      "metadata": {
        "id": "6KYq35TT71ol"
      }
    }
  ]
}